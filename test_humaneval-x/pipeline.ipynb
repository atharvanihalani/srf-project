{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25e28b2a",
   "metadata": {},
   "source": [
    "## Imports + Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edddd561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "from typing import List\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import inspect_ai\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "import torch as t\n",
    "import subprocess\n",
    "import contextlib\n",
    "import shutil\n",
    "import ast\n",
    "import copy\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146feabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect_ai import Task, task\n",
    "from inspect_ai.dataset import Sample, hf_dataset\n",
    "from inspect_ai.util import ExecResult, sandbox\n",
    "from inspect_ai.scorer import CORRECT, INCORRECT, Score, Scorer, Target, accuracy, scorer, stderr\n",
    "from inspect_ai.solver import TaskState, generate\n",
    "from inspect_ai.model import get_model\n",
    "from inspect_ai.log import read_eval_log\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae427e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "login(token = os.environ['HF_TOKEN'])\n",
    "client = OpenAI()\n",
    "async_client = AsyncOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf8ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORT_HELPER = {\n",
    "    \"python\": [\n",
    "        \"import math\",\n",
    "        \"import re\",\n",
    "        \"import sys\",\n",
    "        \"import copy\",\n",
    "        \"import datetime\",\n",
    "        \"import itertools\",\n",
    "        \"import collections\",\n",
    "        \"import heapq\",\n",
    "        \"import statistics\",\n",
    "        \"import functools\",\n",
    "        \"import hashlib\",\n",
    "        \"import numpy\",\n",
    "        \"import numpy as np\",\n",
    "        \"import string\",\n",
    "        \"from typing import *\",\n",
    "        \"from collections import *\",\n",
    "    ],\n",
    "    \"go\"    : [\n",
    "        \"math\",\n",
    "        \"strings\",\n",
    "        \"fmt\",\n",
    "        \"strconv\",\n",
    "        \"time\",\n",
    "        \"bytes\",\n",
    "        \"regexp\",\n",
    "        \"sort\",\n",
    "        \"math/rand\",\n",
    "        \"crypto/md5\",\n",
    "    ],\n",
    "    \"cpp\"   : [\n",
    "        \"#include<stdlib.h>\",\n",
    "        \"#include<algorithm>\",\n",
    "        \"#include<math.h>\",\n",
    "        \"#include<stdio.h>\",\n",
    "        \"#include<vector>\",\n",
    "        \"#include<string>\",\n",
    "        \"#include<climits>\",\n",
    "        \"#include<cstring>\",\n",
    "        \"#include<iostream>\",\n",
    "        \"#include <numeric>\",\n",
    "        \"#include <sstream>\",\n",
    "        \"#include <stack>\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# instruction prepended to code problem\n",
    "HUMANEVAL_INSTRUCTION = \"\"\"\n",
    "Read the following function signature and docstring, and fully implement\n",
    "the function described. Your response should only contain the code for\n",
    "this function.\\n\n",
    "\"\"\"\n",
    "\n",
    "CODE_EXTRACTION_INSTRUCTION = \"\"\"\n",
    "Here is a section of code. Follow these instructions to extract the function body.\n",
    "First, if present, remove any leading package names, import statements, and comments. \n",
    "Next, remove the function signature of the first function you see. \n",
    "If there is a `main` function present, delete that entire function. \n",
    "However, if there are any other functions present, leave them as they are.\n",
    "If the code is in python, ensure the function body is indented properly.\n",
    "\n",
    "Your response should only contain the remaining block of code. \\n\n",
    "\"\"\"\n",
    "\n",
    "LANG_PREFIX = {\n",
    "    \"cpp\"          : \"// language: C++\",\n",
    "    \"java\"         : \"// language: Java\",\n",
    "    \"js\"           : \"// language: JavaScript\",\n",
    "    \"javascript\"   : \"// language: JavaScript\",\n",
    "    \"go\"           : \"// language: Go\",\n",
    "    \"python\"       : \"# language: Python\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab12a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_model = get_model(\n",
    "        'hf/meta-llama/Llama-3.1-8B-Instruct', \n",
    "        device='auto',\n",
    "        torch_dtype=\"auto\"\n",
    ")\n",
    "\n",
    "qwen_coder = get_model(\n",
    "    'hf/Qwen/Qwen2.5-Coder-7B-Instruct',\n",
    "    device=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    ")\n",
    "\n",
    "# deepseek_coder = get_model(\n",
    "#     'hf/deepseek-ai/deepseek-coder-6.7b-instruct',\n",
    "#     device='auto',\n",
    "#     torch_dtype='auto',\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d713f59",
   "metadata": {},
   "source": [
    "### Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb3e266",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "```python\n",
    "\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "prompt_1 = \"\"\"\n",
    "```python\n",
    "import math\n",
    "\n",
    "def right_angle_triangle(a, b, c):\n",
    "    '''\n",
    "    Given the lengths of the three sides of a triangle. Return True if the three\n",
    "    sides form a right-angled triangle, False otherwise.\n",
    "    A right-angled triangle is a triangle in which one angle is right angle or \n",
    "    90 degree.\n",
    "    Example:\n",
    "    right_angle_triangle(3, 4, 5) == True\n",
    "    right_angle_triangle(1, 2, 3) == False\n",
    "    '''\n",
    "    sides = sorted([a, b, c])\n",
    "    return math.isclose(sides[0]**2 + sides[1]**2, sides[2]**2)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "response_1 = \"\"\"\n",
    "```python\n",
    "    sides = sorted([a, b, c])\n",
    "    return math.isclose(sides[0]**2 + sides[1]**2, sides[2]**2)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "prompt_2 = \"\"\"\n",
    "```python\n",
    "def sorted_list_sum(lst):\n",
    "    '''\n",
    "    Deletes strings with odd lengths from a list and returns the resulted list \n",
    "    sorted in ascending order by string length and then alphabetically.\n",
    "\n",
    "    Args:\n",
    "        lst (list): A list of strings.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of strings with odd lengths removed, sorted by length and then alphabetically.\n",
    "    '''\n",
    "    # Filter out strings with odd lengths\n",
    "    even_length_strings = [string for string in lst if len(string) % 2 == 0]\n",
    "    \n",
    "    # Sort the list first by length and then alphabetically\n",
    "    sorted_list = sorted(even_length_strings, key=lambda x: (len(x), x))\n",
    "    \n",
    "    return sorted_list\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "response_2 = \"\"\"\n",
    "```python\n",
    "    # Filter out strings with odd lengths\n",
    "    even_length_strings = [string for string in lst if len(string) % 2 == 0]\n",
    "    \n",
    "    # Sort the list first by length and then alphabetically\n",
    "    sorted_list = sorted(even_length_strings, key=lambda x: (len(x), x))\n",
    "    \n",
    "    return sorted_list\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "prompt_3 = '''\n",
    "```python\n",
    "def words_in_sentence(sentence):\n",
    "    ''''''\n",
    "    Returns a string containing the words from the original sentence whose lengths are prime numbers.\n",
    "    \n",
    "    Args:\n",
    "        sentence (str): A string representing a sentence.\n",
    "    \n",
    "    Returns:\n",
    "        str: A string containing the words from the original sentence whose lengths are prime numbers.\n",
    "    \"\"\"\n",
    "    def is_prime(n):\n",
    "        \"\"\"Checks if a number is prime.\"\"\"\n",
    "        if n < 2:\n",
    "            return False\n",
    "        for i in range(2, int(n ** 0.5) + 1):\n",
    "            if n % i == 0:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    words = sentence.split()\n",
    "    return ' '.join(word for word in words if is_prime(len(word)))\n",
    "    ```\n",
    "    '''\n",
    "\n",
    "response_3 = '''\n",
    "```python\n",
    "    def is_prime(n):\n",
    "        \"\"\"Checks if a number is prime.\"\"\"\n",
    "        if n < 2:\n",
    "            return False\n",
    "        for i in range(2, int(n ** 0.5) + 1):\n",
    "            if n % i == 0:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    words = sentence.split()\n",
    "    return ' '.join(word for word in words if is_prime(len(word)))\n",
    "    ```\n",
    "    '''\n",
    "\n",
    "prompt_4 = '''\n",
    "```python\n",
    "    \"\"\"Evaluate whether the given number n can be written as the sum of exactly 4 positive even numbers\n",
    "    Example\n",
    "    is_equal_to_sum_even(4) == False\n",
    "    is_equal_to_sum_even(6) == False\n",
    "    is_equal_to_sum_even(8) == True\n",
    "    \"\"\"\n",
    "    # The smallest sum of 4 positive even numbers (2 + 2 + 2 + 2) is 8\n",
    "    if n < 8:\n",
    "        return False\n",
    "    \n",
    "    # Since the sum of even numbers is even, n must be even\n",
    "    if n % 2 != 0:\n",
    "        return False\n",
    "    \n",
    "    # If n is at least 8 and is even, it can be expressed as the sum of 4 positive even numbers\n",
    "    return True\n",
    "    ```\n",
    "    '''\n",
    "\n",
    "response_4 = '''\n",
    "```python\n",
    "    # The smallest sum of 4 positive even numbers (2 + 2 + 2 + 2) is 8\n",
    "    if n < 8:\n",
    "        return False\n",
    "    \n",
    "    # Since the sum of even numbers is even, n must be even\n",
    "    if n % 2 != 0:\n",
    "        return False\n",
    "    \n",
    "    # If n is at least 8 and is even, it can be expressed as the sum of 4 positive even numbers\n",
    "    return True\n",
    "    ```\n",
    "    '''\n",
    "\n",
    "prompt_0 = \"\"\"\n",
    "```python\n",
    "    txt = txt.rstrip()  # Remove trailing spaces\n",
    "    if not txt:  # Check if the string is empty after stripping\n",
    "        return False\n",
    "    last_char = txt[-1]  # Get the last character of the string\n",
    "    return last_char.isalpha() and (len(txt) == 1 or txt[-2] == ' ')  # Check conditions\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "response_0 = \"\"\"\n",
    "```python\n",
    "    txt = txt.rstrip()  # Remove trailing spaces\n",
    "    if not txt:  # Check if the string is empty after stripping\n",
    "        return False\n",
    "    last_char = txt[-1]  # Get the last character of the string\n",
    "    return last_char.isalpha() and (len(txt) == 1 or txt[-2] == ' ')  # Check conditions\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "num_prompts = 5\n",
    "\n",
    "PYTHON_PROMPT = [{\n",
    "        'role': 'developer',\n",
    "        'content': CODE_EXTRACTION_INSTRUCTION,\n",
    "    }]\n",
    "\n",
    "for i in range(5):\n",
    "    user_msg = {\n",
    "        'role': 'user',\n",
    "        'content': globals()[f'prompt_{i}'],\n",
    "    }\n",
    "    PYTHON_PROMPT.append(user_msg)\n",
    "\n",
    "    assistant_msg = {\n",
    "        'role': 'assistant',\n",
    "        'content': globals()[f'response_{i}']\n",
    "    }\n",
    "    PYTHON_PROMPT.append(assistant_msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a725ebb6",
   "metadata": {},
   "source": [
    "### Language Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e47b2",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# JavaScript\n",
    "#     apt-get update\n",
    "#     apt-get install -y curl\n",
    "#     curl -fsSL https://deb.nodesource.com/setup_lts.x | bash -\n",
    "#     apt-get install -y nodejs\n",
    "#     verify installation: `node -v` // `npm -v` // `node -e \"console.log('Node.js is working')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0284d1fd",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Java\n",
    "#     apt-get update\n",
    "#     apt-get install -y openjdk-21-jdk\n",
    "# Verify with:  \n",
    "#     java -version\n",
    "#     javac -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4e9f29",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Go\n",
    "#     cd ~/\n",
    "#     GO_VERSION=1.24.5\n",
    "#     wget https://go.dev/dl/go${GO_VERSION}.linux-amd64.tar.gz\n",
    "#     rm -rf /usr/local/go\n",
    "#     tar -C /usr/local -xzf go${GO_VERSION}.linux-amd64.tar.gz\n",
    "#     echo 'export PATH=$PATH:/usr/local/go/bin' >> ~/.bashrc\n",
    "#     export PATH=$PATH:/usr/local/go/bin\n",
    "#     go version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfd5e21",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# C++\n",
    "#     apt-get update\n",
    "#     apt-get install -y g++\n",
    "#     apt-get install -y build-essential\n",
    "#     apt-get install libboost-all-dev\n",
    "#     apt-get install libssl-dev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27c2a4c",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c435c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_jsonl_all(filename: str):\n",
    "    results = []\n",
    "    fp = gzip.open(open(filename, \"rb\"), \"rt\")\n",
    "    for line in fp:\n",
    "        if any(not x.isspace() for x in line):\n",
    "            results.append(json.loads(line))\n",
    "    fp.close()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d9696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_content = stream_jsonl_all('data/python_data.gz')\n",
    "cpp_content = stream_jsonl_all('data/cpp_data.gz')\n",
    "go_content = stream_jsonl_all('data/go_data.gz')\n",
    "java_content = stream_jsonl_all('data/java_data.gz')\n",
    "js_content = stream_jsonl_all('data/js_data.gz')\n",
    "content = [python_content, cpp_content, go_content, java_content, js_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5952979",
   "metadata": {},
   "outputs": [],
   "source": [
    "generations = stream_jsonl_all('data/python_generations.gz')\n",
    "generations[0]['generation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a531c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in content:\n",
    "    print(lang[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5c3a24",
   "metadata": {},
   "source": [
    "## Eval Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f034f0",
   "metadata": {},
   "source": [
    "### Extract Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd2df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_codeblock(completion: str) -> str:\n",
    "    pattern_1 = re.compile(r\"```(?:python|javascript|java|cpp|go)\\n(.*?)```\", re.DOTALL)\n",
    "    pattern_2 = re.compile(r\"```\\n(.*?)```\", re.DOTALL)\n",
    "    matches = pattern_1.findall(completion) + pattern_2.findall(completion)\n",
    "\n",
    "    if matches == []:\n",
    "        return completion\n",
    "    else:\n",
    "        return matches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b8d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def remove_signature(completion):\n",
    "    # prompt = CODE_EXTRACTION_INSTRUCTION + completion\n",
    "    prompt = PYTHON_PROMPT + [{\n",
    "        'role': 'user',\n",
    "        'content': completion\n",
    "    }]\n",
    "\n",
    "    response = await async_client.responses.create(\n",
    "        model='gpt-4.1-mini',\n",
    "        input=prompt,\n",
    "    )\n",
    "\n",
    "    text_out = response.output[-1].content[0].text\n",
    "    return text_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c9d892",
   "metadata": {},
   "source": [
    "### Languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10b7a88",
   "metadata": {},
   "source": [
    "#### CPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2920892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_brackets_cpp(completion):\n",
    "    if '{' in completion[:3]:\n",
    "        completion = completion.replace('{', \"\", 1)\n",
    "\n",
    "    difference = completion.count('{') - completion.count('}') \n",
    "    if difference == 0: \n",
    "        completion += '}'\n",
    "        difference -= 1\n",
    "    if difference != -1: \n",
    "        print('brackets ain\\'t balancing')\n",
    "    \n",
    "    return completion\n",
    "\n",
    "def find_code_cpp(completion: str) -> str:\n",
    "    processed = remove_signature(completion)\n",
    "    processed = identify_codeblock(processed)\n",
    "    processed = balance_brackets_cpp(processed)\n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dedc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_cpp(state, completion):\n",
    "    imports = ''\n",
    "    for s in IMPORT_HELPER['cpp']:\n",
    "        if s not in state.metadata['prompt']:\n",
    "            imports += s + '\\n'\n",
    "\n",
    "    code = imports + \"\\n\" + state.metadata['prompt'] + completion + \"\\n\" + state.metadata['test']\n",
    "    \n",
    "    return code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9114d0d7",
   "metadata": {},
   "source": [
    "#### Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6747847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_brackets_go(completion):\n",
    "    if '{' in completion[:3]:\n",
    "        completion = completion.replace('{', \"\", 1)\n",
    "\n",
    "    difference = completion.count('{') - completion.count('}') \n",
    "    if difference == 0: \n",
    "        completion += '\\n}'\n",
    "        difference -= 1\n",
    "    if difference != -1: \n",
    "        print('brackets ain\\'t balancing')\n",
    "    \n",
    "    return completion\n",
    "\n",
    "def find_code_go(completion: str) -> str:\n",
    "    processed = remove_signature(completion)\n",
    "    processed = identify_codeblock(processed)\n",
    "    processed = balance_brackets_go(processed)\n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3075cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_go(state, completion):\n",
    "    import_string = state.metadata['import']\n",
    "    prompt = state.metadata['prompt'].replace(import_string, '')\n",
    "\n",
    "    test = state.metadata['test']\n",
    "    test_setup = state.metadata['test_setup']\n",
    "    other_pkgs = []\n",
    "\n",
    "    for pkg in IMPORT_HELPER['go']:\n",
    "        if pkg not in test_setup:\n",
    "            p = pkg.split('/')[-1]\n",
    "            if p + '.' in completion:    \n",
    "                other_pkgs.append(f\"\\\"{pkg}\\\"\")\n",
    "    if other_pkgs:\n",
    "        import_other_pkgs = \"import (\\n\" + \"    \".join([p + \"\\n\" for p in other_pkgs]) + \")\"\n",
    "        final_code = test_setup + \"\\n\" + import_other_pkgs + \"\\n\" + prompt + completion + \"\\n\" + test\n",
    "    else:\n",
    "        final_code = test_setup + \"\\n\" + prompt + completion + \"\\n\" + test\n",
    "\n",
    "    return final_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1555b525",
   "metadata": {},
   "source": [
    "#### Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9c510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unindented(lines, full_func):\n",
    "    while (not lines[0]) or (lines[0] == lines[0].lstrip()):\n",
    "        full_func = True\n",
    "    return lines, full_func\n",
    "\n",
    "def remove_signature_java(lines, full_func):\n",
    "    '''\n",
    "    deals with three cases\n",
    "    a) first lines are comments, before method header\n",
    "    b) first line is method-header\n",
    "    c) b), but with incorrect indentation? so header had accidentally been removed?\n",
    "    '''\n",
    "    if not (full_func or lines[0].lstrip()[:6] == 'public'):\n",
    "        return lines\n",
    "    \n",
    "    removed = False\n",
    "    og_lines = copy.deepcopy(lines)\n",
    "    \n",
    "    while not removed:\n",
    "        if lines == []:\n",
    "            return og_lines\n",
    "        \n",
    "        line = lines.pop(0)\n",
    "        if line.lstrip()[:6] == 'public':\n",
    "            removed = True\n",
    "        \n",
    "    return lines\n",
    "\n",
    "def balance_brackets_java(processed):\n",
    "    difference = processed.count('{') - processed.count('}') + 2\n",
    "    assert difference in [0, 1, 2], 'brackets ain\\'t balancing'\n",
    "    return processed + ('}' * difference)\n",
    "\n",
    "def find_code_java(completion: str) -> str:\n",
    "    code = identify_codeblock(completion)\n",
    "    lines = code.splitlines()\n",
    "    lines, full_func = remove_unindented(lines, False)\n",
    "    lines = remove_signature_java(lines, full_func)\n",
    "\n",
    "    processed = '\\n'.join(lines)\n",
    "    processed = balance_brackets_java(processed)\n",
    "    \n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62716e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_java(state, completion):\n",
    "    final_code = state.metadata['prompt'] + completion + \"\\n\\n\" + state.metadata['test'] + \"\\n\"\n",
    "    return final_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8245571c",
   "metadata": {},
   "source": [
    "#### Java [archived]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12cb33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_method_header(lines,):\n",
    "#     '''\n",
    "#     deals with three cases\n",
    "#     a) first lines are comments, before method header\n",
    "#     b) first line is method-header\n",
    "#     c) b), but with incorrect indentation? so header had accidentally been removed?\n",
    "#     '''\n",
    "#     removed = False\n",
    "#     og_lines = copy.deepcopy(lines)\n",
    "    \n",
    "#     while not removed:\n",
    "#         if lines == []:\n",
    "#             return og_lines\n",
    "        \n",
    "#         line = lines.pop(0)\n",
    "#         if line.lstrip()[:6] == 'public':\n",
    "#             removed = True\n",
    "        \n",
    "#     return lines\n",
    "\n",
    "# def balance_brackets(lines):\n",
    "#     final_code = '\\n'.join(lines)\n",
    "#     difference = final_code.count('{') - final_code.count('}') + 2\n",
    "#     assert difference in [0, 1, 2], 'brackets ain\\'t balancing'\n",
    "#     return final_code + ('}' * difference)\n",
    "\n",
    "# def remove_unindented(lines, full_func):\n",
    "#     import_statements = []\n",
    "#     while (not lines[0]) or (lines[0] == lines[0].lstrip()):\n",
    "#         line = lines.pop(0)\n",
    "#         full_func = True\n",
    "#         if 'import' in line: import_statements.append(line)\n",
    "    \n",
    "#     return lines, import_statements, full_func\n",
    "\n",
    "# def find_code_java(completion: str) -> str:\n",
    "#     code = identify_codeblock(completion)\n",
    "#     lines = code.splitlines()\n",
    "\n",
    "#     lines, import_statements, full_func = remove_unindented(lines, False)\n",
    "\n",
    "#     if full_func or lines[0].lstrip()[:6] == 'public':\n",
    "#         lines = remove_method_header(lines)\n",
    "\n",
    "#     processed_completion = balance_brackets(lines)\n",
    "#     import_statements = '\\n'.join(import_statements)\n",
    "    \n",
    "#     return processed_completion, import_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a99bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_final_java(imports, state, completion):\n",
    "#     final_code = imports + '\\n' + state.metadata['prompt'] + completion + \"\\n\\n\" + state.metadata['test'] + \"\\n\"\n",
    "#     return final_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51f2087",
   "metadata": {},
   "source": [
    "#### JavaScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e7a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_signature_js(code: str) -> str:\n",
    "    lines = code.splitlines()\n",
    "    found = False\n",
    "    for line in lines:\n",
    "        if line.lstrip().startswith('const'):\n",
    "            lines.remove(line)\n",
    "            found = True\n",
    "            break  \n",
    "\n",
    "    if not found: \n",
    "        print('error extracting function body')\n",
    "        return 'errormsg'\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def find_code_js(completion: str) -> str:\n",
    "    processed = identify_codeblock(completion)\n",
    "    processed = remove_signature_js(processed)\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78123532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_js(state, completion):\n",
    "    final_code = state.metadata['prompt'] + completion + \"\\n\\n\" + state.metadata['test'] + \"\\n\"\n",
    "    return final_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f360fc",
   "metadata": {},
   "source": [
    "#### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372bc486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_signature_python(code: str) -> str:\n",
    "    try:\n",
    "        tree = ast.parse(code)\n",
    "        for node in tree.body:\n",
    "            if not isinstance(node, ast.FunctionDef):\n",
    "                continue\n",
    "            code_lines = code.splitlines()\n",
    "            start = node.body[0].lineno - 1\n",
    "            end = node.body[-1].end_lineno\n",
    "            body_lines = code_lines[start:end]\n",
    "            return \"\\n\".join(body_lines)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting function body: {e}\")\n",
    "        return \"errormsg\"\n",
    "    \n",
    "async def find_code_python(completion):\n",
    "    processed = identify_codeblock(completion)\n",
    "\n",
    "    processed = await remove_signature(processed)\n",
    "    processed = identify_codeblock(processed)\n",
    "\n",
    "    # processed = remove_signature_python(processed)\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefc1b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_python(state, completion):\n",
    "    imports = \"\\n\".join(IMPORT_HELPER[\"python\"]) + \"\\n\"\n",
    "    final_code = imports + state.metadata['prompt'] + completion + \"\\n\" + state.metadata['test'] + \"\\n\"\n",
    "    return final_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dffe12",
   "metadata": {},
   "source": [
    "### Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5278778",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_final(state, lang, task_id):\n",
    "    model_completion = state.output.completion\n",
    "\n",
    "    process_code = globals()[f'find_code_{lang}']\n",
    "    processed_completion = await process_code(model_completion)\n",
    "\n",
    "    final = globals()[f'get_final_{lang}']\n",
    "    final_code = final(state, processed_completion)\n",
    "\n",
    "    if 'errormsg' in final_code:\n",
    "        print(f'error in sample: {task_id}')\n",
    "    \n",
    "    return model_completion, processed_completion, final_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333ea676",
   "metadata": {},
   "source": [
    "### Scorers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5785fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def python_scorer(final_code, *args):\n",
    "    try:\n",
    "        result = await sandbox().exec(\n",
    "            cmd=[\"python\", \"-c\", final_code],\n",
    "            timeout=30,\n",
    "        )\n",
    "    except TimeoutError:\n",
    "        result = ExecResult(False, 1, \"\", \"Verification timed out.\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8fdfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def js_scorer(final_code, *args):\n",
    "    try:\n",
    "        result = await sandbox().exec(\n",
    "            cmd=[\"node\", \"-e\", final_code],\n",
    "            timeout=30,\n",
    "        )\n",
    "    except TimeoutError:\n",
    "        result = ExecResult(False, 1, \"\", \"Verification timed out.\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a340183",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def go_scorer(final_code, idx, tmp_dir):\n",
    "    if not os.path.exists(tmp_dir):\n",
    "        os.makedirs(tmp_dir, exist_ok=True)\n",
    "    file = os.path.join(tmp_dir, 'main_test.go')\n",
    "\n",
    "    with contextlib.chdir(tmp_dir):\n",
    "        open(file, 'w').write(final_code)\n",
    "        if not os.path.exists('go.mod'):\n",
    "            try:\n",
    "                subprocess.run(\n",
    "                    ['/usr/local/go/bin/go', 'mod', 'init', f'example.com/tmpmod_{idx}'],\n",
    "                    check=True, \n",
    "                    capture_output=True,\n",
    "                )\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(\"Error running go mod init:\")\n",
    "                print(e.stderr)\n",
    "        subprocess.run(\n",
    "            ['/usr/local/go/bin/go', 'mod', 'tidy'], \n",
    "            check=True, \n",
    "            capture_output=True,\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        result = await sandbox().exec(\n",
    "            cmd=[\"/usr/local/go/bin/go\", \"test\", file],\n",
    "            timeout=30,\n",
    "            cwd=tmp_dir\n",
    "        )\n",
    "    except TimeoutError:\n",
    "        result = ExecResult(False, 1, \"\", \"Verification timed out.\")\n",
    "\n",
    "    shutil.rmtree(tmp_dir)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcafb6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def java_scorer(final_code, idx, tmp_dir):\n",
    "    if not os.path.exists(tmp_dir):\n",
    "        os.makedirs(tmp_dir, exist_ok=True)\n",
    "    file = os.path.join(tmp_dir, 'Main.java')\n",
    "\n",
    "    with contextlib.chdir(tmp_dir):\n",
    "        open(file, 'w').write(final_code)\n",
    "    \n",
    "    try:\n",
    "        compile_proc = subprocess.run(\n",
    "            [\"javac\", \"Main.java\"],\n",
    "            cwd=tmp_dir,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=30  \n",
    "        )\n",
    "        if compile_proc.returncode != 0:\n",
    "            print(f\"Compilation failed! Idx: {idx}\")\n",
    "            print(\"stderr:\", compile_proc.stderr)\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"Compilation timed out!\")\n",
    "    except Exception as e:\n",
    "        print(\"Compilation error:\", e)\n",
    "\n",
    "    try:\n",
    "        result = await sandbox().exec(\n",
    "            cmd=[\"java\", \"-cp\", tmp_dir, \"Main\"],\n",
    "            timeout=30,\n",
    "        )\n",
    "    except TimeoutError:\n",
    "        result = ExecResult(False, 1, \"\", \"Verification timed out.\")\n",
    "\n",
    "    shutil.rmtree(tmp_dir)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f6bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def cpp_scorer(final_code, idx, tmp_dir):\n",
    "    if not os.path.exists(tmp_dir):\n",
    "        os.makedirs(tmp_dir, exist_ok=True)\n",
    "    file = os.path.join(tmp_dir, 'test.cpp')\n",
    "    executable = os.path.join(tmp_dir, 'test.out')\n",
    "\n",
    "    open(file, 'w').write(final_code)\n",
    "    \n",
    "    try:\n",
    "        compile_proc = subprocess.run(\n",
    "            [\"g++\", \"-std=c++17\", file, \"-o\", executable, '-lssl', '-lcrypto'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=30  # seconds, adjust as needed\n",
    "        )\n",
    "        if compile_proc.returncode != 0:\n",
    "            print(f\"Compilation failed! task number: {idx}\")\n",
    "            print(\"stderr:\", compile_proc.stderr)\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"Compilation timed out!\")\n",
    "\n",
    "    if os.path.exists(executable):\n",
    "        try:\n",
    "            result = await sandbox().exec(\n",
    "                cmd=[executable],\n",
    "                timeout=30\n",
    "            )\n",
    "        except TimeoutError:\n",
    "            result = ExecResult(False, 1, \"\", \"Verification timed out.\")\n",
    "        except Exception as e:\n",
    "            print(f'execution failed cuz of: {e}')\n",
    "    else:\n",
    "        result = ExecResult(False, 1, \"\", \"Compiler Error\")\n",
    "\n",
    "    shutil.rmtree(tmp_dir)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f3b45",
   "metadata": {},
   "source": [
    "### Inspect Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a859b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lang_idx(task_id: str):\n",
    "    lang, idx = task_id.split('/')\n",
    "    lang = lang.lower()\n",
    "    if lang == 'javascript':\n",
    "        lang = 'js'\n",
    "    idx = int(idx)\n",
    "\n",
    "    return lang, idx\n",
    "\n",
    "@scorer(metrics=[accuracy(), stderr()])\n",
    "def main_scorer() -> Scorer:\n",
    "    async def score(state: TaskState, target: Target) -> Score:\n",
    "        task_id = state.sample_id\n",
    "        lang, idx = get_lang_idx(task_id)\n",
    "\n",
    "        model_completion, processed_completion, final_code = await get_final(state, lang, task_id)\n",
    "\n",
    "        tmp_dir = f'/root/srf-project/test_humaneval-x/tmp/test_{idx}/'\n",
    "        my_scorer = globals()[f'{lang}_scorer']\n",
    "        result = await my_scorer(final_code, idx, tmp_dir)\n",
    "\n",
    "        success = result.success and (result.stderr == '')\n",
    "        \n",
    "        return Score(\n",
    "            value=CORRECT if success else INCORRECT,\n",
    "            explanation=\"\".join(\n",
    "                [\"The following verification code was executed:\\n\\n\"]\n",
    "                + [final_code]\n",
    "                + [f\"\\nThe submission was incorrect\\n\\n{result.stderr}\"]\n",
    "                if not result.success\n",
    "                else [\"\"]\n",
    "            ),\n",
    "            metadata={\n",
    "                'completion': model_completion,\n",
    "                'processed': processed_completion,\n",
    "                'final_code': final_code,\n",
    "                'idx': idx,\n",
    "                'task_id': task_id,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b0d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'python'\n",
    "\n",
    "def humaneval_record_to_sample(record):\n",
    "    model_input = HUMANEVAL_INSTRUCTION + LANG_PREFIX[language] + '\\n' + record['prompt'] \n",
    "\n",
    "    idx = int(record['task_id'].split('/')[-1])\n",
    "\n",
    "    metadata = {\n",
    "        \"prompt\": record[\"prompt\"],\n",
    "        \"test\": record[\"test\"],\n",
    "    }\n",
    "    if language == 'go':\n",
    "        metadata['import'] = go_content[idx]['import']\n",
    "        metadata['test_setup'] = go_content[idx]['test_setup']\n",
    "    \n",
    "    return Sample(\n",
    "        id=record[\"task_id\"],\n",
    "        input=model_input,\n",
    "        target=record[\"canonical_solution\"],\n",
    "        metadata=metadata,\n",
    "    )\n",
    "\n",
    "humaneval_dataset = hf_dataset(\n",
    "    path = 'THUDM/humaneval-x',\n",
    "    name = language,\n",
    "    split = 'test',\n",
    "    sample_fields = humaneval_record_to_sample,\n",
    "    trust = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d1d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 30\n",
    "\n",
    "@task\n",
    "def humaneval():\n",
    "    return Task(\n",
    "        dataset = humaneval_dataset[-samples:],\n",
    "        solver = generate(),\n",
    "        scorer = main_scorer(),\n",
    "        sandbox = 'local',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac9121b",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfee2300",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "inspect_ai.eval(\n",
    "    humaneval(), \n",
    "    model = 'openai/gpt-4o-mini', \n",
    "    epochs = epochs,\n",
    "    log_dir = '/root/srf-project/test_humaneval-x/pipeline_check/python/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5709a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/root/srf-project/test_humaneval-x/pipeline_check/python/llama_8b.eval'\n",
    "log = read_eval_log(path)\n",
    "\n",
    "def eval_duration(log):\n",
    "    start_time = log.stats.started_at\n",
    "    start_time = start_time.split('T')[-1].split('+')[0]\n",
    "\n",
    "    end_time = log.stats.completed_at\n",
    "    end_time = end_time.split('T')[-1].split('+')[0]\n",
    "    \n",
    "    fmt = \"%H:%M:%S\"\n",
    "    t1 = datetime.strptime(start_time, fmt)\n",
    "    t2 = datetime.strptime(end_time, fmt)\n",
    "\n",
    "    duration = (t2-t1).seconds\n",
    "\n",
    "    return f'{duration} seconds'\n",
    "\n",
    "def eval_score(log):\n",
    "    score = log.results.scores[0].metrics['accuracy'].value\n",
    "    return f'{score * 100:.2f}%'\n",
    "    \n",
    "print(eval_duration(log))\n",
    "print(eval_score(log))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
