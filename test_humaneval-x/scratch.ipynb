{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73c1567d",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4417b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI, AsyncOpenAI\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, AutoModelForSequenceClassification, DataCollatorForLanguageModeling\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "import torch as t\n",
    "import asyncio\n",
    "import os\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import bitsandbytes\n",
    "from datasets import ClassLabel\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import wandb\n",
    "import einops\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f4a4c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "login(token = os.environ['HF_TOKEN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a735291",
   "metadata": {},
   "source": [
    "## FT Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc68c133",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b63aeab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(lang):\n",
    "    dataset = load_dataset('iNeil77/CodeNet', lang, split='train')\n",
    "    dataset = dataset.select_columns(['p_id', 'language', 'status', 'code'])\n",
    "    dataset = dataset.filter(lambda x: x['status']=='Accepted')\n",
    "    return dataset\n",
    "\n",
    "my_dataset = get_dataset('Java')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "251d8287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     idx = random.randint(0, dataset_cpp.num_rows)\n",
    "#     code = dataset_cpp[idx]['code']\n",
    "#     print(code)\n",
    "#     print('--x---x---x--\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9815e22",
   "metadata": {},
   "source": [
    "### Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f64568b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a78898099a49b4a09dc8985674129d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, pad_side=\"left\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    device_map=\"auto\", \n",
    "    torch_dtype=\"auto\"\n",
    "    # load_in_4bit=True, \n",
    "    # bnb_4bit_compute_dtype=t.bfloat16,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07bde88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853218b22ee44075a74d59e64f2c0bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/348362 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_lengths = []\n",
    "test = True\n",
    "\n",
    "def tokenize(record):\n",
    "    global test\n",
    "\n",
    "    code = record['code']\n",
    "    tokens = tokenizer(\n",
    "        code, \n",
    "        truncation=True,\n",
    "        max_length=1024,\n",
    "    )\n",
    "\n",
    "    tokseq = tokens['input_ids']\n",
    "    for toks in tokseq:\n",
    "        seq_lengths.append(len(toks))\n",
    "\n",
    "    # seq_lengths.append(len(tokens['input_ids']))\n",
    "    return tokens\n",
    "\n",
    "tokenized_dataset = my_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a0f7e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('seq_lengths.json', 'w') as f:\n",
    "    json.dump(seq_lengths, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5d0dae72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342.11280794116465"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(seq_lengths) / len(seq_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cceb45e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10302., 44000., 47714., 37685., 30091., 21539., 16306., 12920.,\n",
       "        10868.,  8993.,  7649.,  6659.,  5930.,  5057.,  4309.,  4135.,\n",
       "         3755.,  3681.,  3358.,  3254.,  3258.,  3075.,  2893.,  2727.,\n",
       "         2528.,  2416.,  2048.,  1929.,  1782., 37501.]),\n",
       " array([  27.        ,   60.23333333,   93.46666667,  126.7       ,\n",
       "         159.93333333,  193.16666667,  226.4       ,  259.63333333,\n",
       "         292.86666667,  326.1       ,  359.33333333,  392.56666667,\n",
       "         425.8       ,  459.03333333,  492.26666667,  525.5       ,\n",
       "         558.73333333,  591.96666667,  625.2       ,  658.43333333,\n",
       "         691.66666667,  724.9       ,  758.13333333,  791.36666667,\n",
       "         824.6       ,  857.83333333,  891.06666667,  924.3       ,\n",
       "         957.53333333,  990.76666667, 1024.        ]),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGiCAYAAAAFotdwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAALaJJREFUeJzt3Xt0VeWd//FPEnJOEvEkkJQEJIF0cLjITUIJx9t4SYk0OiqMCx2wKSAuaOIY4gJNq+BlnDDMAKJG6FQhzlIKMlNtBQqmQVBKuAWiXALVkU4yykkMkEQQkpA8vz+6sn8cuegJIZeH92utvZZnP99nn2c/Ls1n7b2ffYKMMUYAAACWCW7vAQAAAFwOhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYKWAQs4zzzyjoKAgv23AgAFO++nTp5WRkaHo6Gh17dpV48ePV0VFhd8xysrKlJaWpoiICPXo0UOzZs3SmTNn/Go2bdqkESNGyO12q1+/fsrPzz9nLHl5eerbt6/CwsKUnJysHTt2BHIqAADAcgFfybnuuut05MgRZ9uyZYvTNnPmTL333ntavXq1Nm/erC+//FLjxo1z2hsbG5WWlqb6+npt3bpVb7zxhvLz8zVnzhyn5vDhw0pLS9Ntt92mkpISZWVl6eGHH9aGDRucmlWrVik7O1tz587V7t27NWzYMKWmpqqysrKl8wAAAGxjAjB37lwzbNiw87ZVV1eb0NBQs3r1amdfaWmpkWSKioqMMcasW7fOBAcHG5/P59QsWbLEeDweU1dXZ4wxZvbs2ea6667zO/aECRNMamqq83nUqFEmIyPD+dzY2Gh69eplcnNzAzkdAABgsS6BhqJPP/1UvXr1UlhYmLxer3Jzc5WQkKDi4mI1NDQoJSXFqR0wYIASEhJUVFSk0aNHq6ioSEOGDFFsbKxTk5qaqhkzZmj//v26/vrrVVRU5HeM5pqsrCxJUn19vYqLi5WTk+O0BwcHKyUlRUVFRRcde11dnerq6pzPTU1NOnbsmKKjoxUUFBToVAAAgHZgjNHXX3+tXr16KTj4wjelAgo5ycnJys/PV//+/XXkyBE9++yzuvnmm7Vv3z75fD65XC5FRUX59YmNjZXP55Mk+Xw+v4DT3N7cdrGa2tpanTp1SsePH1djY+N5aw4ePHjR8efm5urZZ58N5JQBAEAHVV5ert69e1+wPaCQM3bsWOefhw4dquTkZPXp00dvv/22wsPDWz7KNpKTk6Ps7Gznc01NjRISElReXi6Px9OOIwMAAN9XbW2t4uPjdfXVV1+0LuDbVWeLiorS3/7t3+qzzz7Tj3/8Y9XX16u6utrvak5FRYXi4uIkSXFxceesgmpefXV2zbdXZFVUVMjj8Sg8PFwhISEKCQk5b03zMS7E7XbL7Xafs9/j8RByAADoZL7rUZNLek/OiRMn9D//8z/q2bOnkpKSFBoaqsLCQqf90KFDKisrk9frlSR5vV7t3bvXbxVUQUGBPB6PBg0a5NScfYzmmuZjuFwuJSUl+dU0NTWpsLDQqQEAAAhoddXjjz9uNm3aZA4fPmz+9Kc/mZSUFBMTE2MqKyuNMcZMnz7dJCQkmI0bN5pdu3YZr9drvF6v0//MmTNm8ODBZsyYMaakpMSsX7/e/OAHPzA5OTlOzeeff24iIiLMrFmzTGlpqcnLyzMhISFm/fr1Ts3KlSuN2+02+fn55sCBA+aRRx4xUVFRfqu2vo+amhojydTU1ATUDwAAtJ/v+/c7oJAzYcIE07NnT+Nyucw111xjJkyYYD777DOn/dSpU+bnP/+56datm4mIiDD33XefOXLkiN8x/vKXv5ixY8ea8PBwExMTYx5//HHT0NDgV/PBBx+Y4cOHG5fLZX74wx+a5cuXnzOWl19+2SQkJBiXy2VGjRpltm3bFsipGGMIOQAAdEbf9+93kDHGtO+1pPZTW1uryMhI1dTU8EwOAACdxPf9+81vVwEAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAK13Sr5Cj4ykrK1NVVVWL+sbExCghIaGVRwQAQPsg5FikrKxM/QcM1OlT37Sof1h4hA4dLCXoAACsQMixSFVVlU6f+kbRdz2u0Oj4gPo2HC3X0TULVFVVRcgBAFiBkGOh0Oh4ueP6tfcwAABoVzx4DAAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWKlLew8A5yorK1NVVVXA/UpLSy/DaAAA6JwIOR1MWVmZ+g8YqNOnvmnvoQAA0KkRcjqYqqoqnT71jaLvelyh0fEB9T31+S7VfPTmZRoZAACdCyGngwqNjpc7rl9AfRqOll+m0QAA0Pnw4DEAALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVLinkzJs3T0FBQcrKynL2nT59WhkZGYqOjlbXrl01fvx4VVRU+PUrKytTWlqaIiIi1KNHD82aNUtnzpzxq9m0aZNGjBght9utfv36KT8//5zvz8vLU9++fRUWFqbk5GTt2LHjUk4HAABYpMUhZ+fOnfrVr36loUOH+u2fOXOm3nvvPa1evVqbN2/Wl19+qXHjxjntjY2NSktLU319vbZu3ao33nhD+fn5mjNnjlNz+PBhpaWl6bbbblNJSYmysrL08MMPa8OGDU7NqlWrlJ2drblz52r37t0aNmyYUlNTVVlZ2dJTAgAAFmlRyDlx4oQmTpyoX//61+rWrZuzv6amRq+//roWLlyo22+/XUlJSVq+fLm2bt2qbdu2SZLef/99HThwQG+++aaGDx+usWPH6vnnn1deXp7q6+slSUuXLlViYqIWLFiggQMHKjMzU//wD/+gRYsWOd+1cOFCTZs2TZMnT9agQYO0dOlSRUREaNmyZZcyHwAAwBItCjkZGRlKS0tTSkqK3/7i4mI1NDT47R8wYIASEhJUVFQkSSoqKtKQIUMUGxvr1KSmpqq2tlb79+93ar597NTUVOcY9fX1Ki4u9qsJDg5WSkqKU3M+dXV1qq2t9dsAAICdugTaYeXKldq9e7d27tx5TpvP55PL5VJUVJTf/tjYWPl8Pqfm7IDT3N7cdrGa2tpanTp1SsePH1djY+N5aw4ePHjBsefm5urZZ5/9ficKAAA6tYCu5JSXl+uxxx7TW2+9pbCwsMs1pssmJydHNTU1zlZeXt7eQwIAAJdJQCGnuLhYlZWVGjFihLp06aIuXbpo8+bNeumll9SlSxfFxsaqvr5e1dXVfv0qKioUFxcnSYqLiztntVXz5++q8Xg8Cg8PV0xMjEJCQs5b03yM83G73fJ4PH4bAACwU0Ah54477tDevXtVUlLibCNHjtTEiROdfw4NDVVhYaHT59ChQyorK5PX65Ukeb1e7d27128VVEFBgTwejwYNGuTUnH2M5prmY7hcLiUlJfnVNDU1qbCw0KkBAABXtoCeybn66qs1ePBgv31XXXWVoqOjnf1Tp05Vdna2unfvLo/Ho0cffVRer1ejR4+WJI0ZM0aDBg3SQw89pPnz58vn8+mpp55SRkaG3G63JGn69Ol65ZVXNHv2bE2ZMkUbN27U22+/rbVr1zrfm52drfT0dI0cOVKjRo3Siy++qJMnT2ry5MmXNCEAAMAOAT94/F0WLVqk4OBgjR8/XnV1dUpNTdWrr77qtIeEhGjNmjWaMWOGvF6vrrrqKqWnp+u5555zahITE7V27VrNnDlTixcvVu/evfXaa68pNTXVqZkwYYK++uorzZkzRz6fT8OHD9f69evPeRgZAABcmS455GzatMnvc1hYmPLy8pSXl3fBPn369NG6desuetxbb71Ve/bsuWhNZmamMjMzv/dYAQDAlYPfrgIAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAVmr1n3VA51ZaWtqifjExMUpISGjl0QAA0HKEHEiSGk8cl4KCNGnSpBb1DwuP0KGDpQQdAECHQciBJKmp7oRkjKLvelyh0fEB9W04Wq6jaxaoqqqKkAMAlikrK1NVVVWL+rb3VX5CDvyERsfLHdevvYcBAOgAysrK1H/AQJ0+9U2L+rf3VX5CDgAAOK+qqiqdPvVNp73KT8gBAAAX1Vmv8rOEHAAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsFJAIWfJkiUaOnSoPB6PPB6PvF6v/vCHPzjtp0+fVkZGhqKjo9W1a1eNHz9eFRUVfscoKytTWlqaIiIi1KNHD82aNUtnzpzxq9m0aZNGjBght9utfv36KT8//5yx5OXlqW/fvgoLC1NycrJ27NgRyKkAAADLBRRyevfurXnz5qm4uFi7du3S7bffrnvuuUf79++XJM2cOVPvvfeeVq9erc2bN+vLL7/UuHHjnP6NjY1KS0tTfX29tm7dqjfeeEP5+fmaM2eOU3P48GGlpaXptttuU0lJibKysvTwww9rw4YNTs2qVauUnZ2tuXPnavfu3Ro2bJhSU1NVWVl5qfMBAAAs0SWQ4rvvvtvv8wsvvKAlS5Zo27Zt6t27t15//XWtWLFCt99+uyRp+fLlGjhwoLZt26bRo0fr/fff14EDB/THP/5RsbGxGj58uJ5//nk98cQTeuaZZ+RyubR06VIlJiZqwYIFkqSBAwdqy5YtWrRokVJTUyVJCxcu1LRp0zR58mRJ0tKlS7V27VotW7ZMTz755CVPClqmtLS0Rf1iYmKUkJDQyqMBAFzpAgo5Z2tsbNTq1at18uRJeb1eFRcXq6GhQSkpKU7NgAEDlJCQoKKiIo0ePVpFRUUaMmSIYmNjnZrU1FTNmDFD+/fv1/XXX6+ioiK/YzTXZGVlSZLq6+tVXFysnJwcpz04OFgpKSkqKiq66Jjr6upUV1fnfK6trW3p6eMsjSeOS0FBmjRpUov6h4VH6NDBUoIOAKBVBRxy9u7dK6/Xq9OnT6tr16565513NGjQIJWUlMjlcikqKsqvPjY2Vj6fT5Lk8/n8Ak5ze3PbxWpqa2t16tQpHT9+XI2NjeetOXjw4EXHnpubq2effTbQU8Z3aKo7IRmj6LseV2h0fEB9G46W6+iaBaqqqiLkAABaVcAhp3///iopKVFNTY3+67/+S+np6dq8efPlGFury8nJUXZ2tvO5trZW8fGB/VHGhYVGx8sd16+9hwEAgKQWhByXy6V+/f76hywpKUk7d+7U4sWLNWHCBNXX16u6utrvak5FRYXi4uIkSXFxceesgmpefXV2zbdXZFVUVMjj8Sg8PFwhISEKCQk5b03zMS7E7XbL7XYHesoAAKATuuT35DQ1Namurk5JSUkKDQ1VYWGh03bo0CGVlZXJ6/VKkrxer/bu3eu3CqqgoEAej0eDBg1yas4+RnNN8zFcLpeSkpL8apqamlRYWOjUAAAABHQlJycnR2PHjlVCQoK+/vprrVixQps2bdKGDRsUGRmpqVOnKjs7W927d5fH49Gjjz4qr9er0aNHS5LGjBmjQYMG6aGHHtL8+fPl8/n01FNPKSMjw7nCMn36dL3yyiuaPXu2pkyZoo0bN+rtt9/W2rVrnXFkZ2crPT1dI0eO1KhRo/Tiiy/q5MmTzmorAACAgEJOZWWlfvrTn+rIkSOKjIzU0KFDtWHDBv34xz+WJC1atEjBwcEaP3686urqlJqaqldffdXpHxISojVr1mjGjBnyer266qqrlJ6erueee86pSUxM1Nq1azVz5kwtXrxYvXv31muvveYsH5ekCRMm6KuvvtKcOXPk8/k0fPhwrV+//pyHkQEAwJUroJDz+uuvX7Q9LCxMeXl5ysvLu2BNnz59tG7duose59Zbb9WePXsuWpOZmanMzMyL1gAAgCsXv10FAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGClLu09AECSSktLW9QvJiZGCQkJrTwaAIANCDloV40njktBQZo0aVKL+oeFR+jQwVKCDgDgHIQctKumuhOSMYq+63GFRscH1LfhaLmOrlmgqqoqQg4A4ByEHHQIodHxcsf1a+9hAAAswoPHAADASoQcAABgJUIOAACwEiEHAABYKaCQk5ubqx/96Ee6+uqr1aNHD9177706dOiQX83p06eVkZGh6Ohode3aVePHj1dFRYVfTVlZmdLS0hQREaEePXpo1qxZOnPmjF/Npk2bNGLECLndbvXr10/5+fnnjCcvL099+/ZVWFiYkpOTtWPHjkBOBwAAWCygkLN582ZlZGRo27ZtKigoUENDg8aMGaOTJ086NTNnztR7772n1atXa/Pmzfryyy81btw4p72xsVFpaWmqr6/X1q1b9cYbbyg/P19z5sxxag4fPqy0tDTddtttKikpUVZWlh5++GFt2LDBqVm1apWys7M1d+5c7d69W8OGDVNqaqoqKysvZT4AAIAlAlpCvn79er/P+fn56tGjh4qLi3XLLbeopqZGr7/+ulasWKHbb79dkrR8+XINHDhQ27Zt0+jRo/X+++/rwIED+uMf/6jY2FgNHz5czz//vJ544gk988wzcrlcWrp0qRITE7VgwQJJ0sCBA7VlyxYtWrRIqampkqSFCxdq2rRpmjx5siRp6dKlWrt2rZYtW6Ynn3zykicGAAB0bpf0TE5NTY0kqXv37pKk4uJiNTQ0KCUlxakZMGCAEhISVFRUJEkqKirSkCFDFBsb69SkpqaqtrZW+/fvd2rOPkZzTfMx6uvrVVxc7FcTHByslJQUpwYAAFzZWvwywKamJmVlZenGG2/U4MGDJUk+n08ul0tRUVF+tbGxsfL5fE7N2QGnub257WI1tbW1OnXqlI4fP67Gxsbz1hw8ePCCY66rq1NdXZ3zuba2NoAzBgAAnUmLr+RkZGRo3759WrlyZWuO57LKzc1VZGSks8XHB/YzAgAAoPNoUcjJzMzUmjVr9MEHH6h3797O/ri4ONXX16u6utqvvqKiQnFxcU7Nt1dbNX/+rhqPx6Pw8HDFxMQoJCTkvDXNxzifnJwc1dTUOFt5eXlgJw4AADqNgEKOMUaZmZl65513tHHjRiUmJvq1JyUlKTQ0VIWFhc6+Q4cOqaysTF6vV5Lk9Xq1d+9ev1VQBQUF8ng8GjRokFNz9jGaa5qP4XK5lJSU5FfT1NSkwsJCp+Z83G63PB6P3wYAAOwU0DM5GRkZWrFihX73u9/p6quvdp6hiYyMVHh4uCIjIzV16lRlZ2ere/fu8ng8evTRR+X1ejV69GhJ0pgxYzRo0CA99NBDmj9/vnw+n5566illZGTI7XZLkqZPn65XXnlFs2fP1pQpU7Rx40a9/fbbWrt2rTOW7Oxspaena+TIkRo1apRefPFFnTx50lltBQAArmwBhZwlS5ZIkm699Va//cuXL9fPfvYzSdKiRYsUHBys8ePHq66uTqmpqXr11Ved2pCQEK1Zs0YzZsyQ1+vVVVddpfT0dD333HNOTWJiotauXauZM2dq8eLF6t27t1577TVn+bgkTZgwQV999ZXmzJkjn8+n4cOHa/369ec8jAwAAK5MAYUcY8x31oSFhSkvL095eXkXrOnTp4/WrVt30ePceuut2rNnz0VrMjMzlZmZ+Z1jAgAAVx5+uwoAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArdWnvAQCXqrS0tEX9YmJilJCQ0MqjAQB0FIQcdFqNJ45LQUGaNGlSi/qHhUfo0MFSgg4AWIqQg06rqe6EZIyi73pcodHxAfVtOFquo2sWqKqqipADAJYi5KDTC42OlzuuX3sPAwDQwfDgMQAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACt1ae8BAO2ptLS0Rf1iYmKUkJDQyqMBALQmQg6uSI0njktBQZo0aVKL+oeFR+jQwVKCDgB0YIQcXJGa6k5Ixij6rscVGh0fUN+Go+U6umaBqqqqCDkA0IERcnBFC42OlzuuX3sPAwBwGfDgMQAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsxG9XAS1UWlraon4xMTH8sCcAtAFCDhCgxhPHpaAgTZo0qUX9w8IjdOhgKUEHAC4zQg4QoKa6E5Ixir7rcYVGxwfUt+FouY6uWaCqqipCDgBcZgE/k/Phhx/q7rvvVq9evRQUFKR3333Xr90Yozlz5qhnz54KDw9XSkqKPv30U7+aY8eOaeLEifJ4PIqKitLUqVN14sQJv5pPPvlEN998s8LCwhQfH6/58+efM5bVq1drwIABCgsL05AhQ7Ru3bpATwdosdDoeLnj+gW0BRqKAAAtF/CVnJMnT2rYsGGaMmWKxo0bd077/Pnz9dJLL+mNN95QYmKinn76aaWmpurAgQMKCwuTJE2cOFFHjhxRQUGBGhoaNHnyZD3yyCNasWKFJKm2tlZjxoxRSkqKli5dqr1792rKlCmKiorSI488IknaunWrHnzwQeXm5uquu+7SihUrdO+992r37t0aPHjwpcxJqygrK1NVVVXA/Vr6nAcAAPAXcMgZO3asxo4de942Y4xefPFFPfXUU7rnnnskSf/5n/+p2NhYvfvuu3rggQdUWlqq9evXa+fOnRo5cqQk6eWXX9ZPfvIT/fu//7t69eqlt956S/X19Vq2bJlcLpeuu+46lZSUaOHChU7IWbx4se68807NmjVLkvT888+roKBAr7zyipYuXdqiyWgtZWVl6j9goE6f+qZdxwEAwJWsVZ/JOXz4sHw+n1JSUpx9kZGRSk5OVlFRkR544AEVFRUpKirKCTiSlJKSouDgYG3fvl333XefioqKdMstt8jlcjk1qamp+td//VcdP35c3bp1U1FRkbKzs/2+PzU19ZzbZ+2hqqpKp09906JnNk59vks1H715mUYGAMCVo1VDjs/nkyTFxsb67Y+NjXXafD6fevTo4T+ILl3UvXt3v5rExMRzjtHc1q1bN/l8vot+z/nU1dWprq7O+VxbWxvI6QWs+ZmNQDQcLb9MowEA4MpyRb0MMDc3V5GRkc4WH89DoAAA2KpVQ05cXJwkqaKiwm9/RUWF0xYXF6fKykq/9jNnzujYsWN+Nec7xtnfcaGa5vbzycnJUU1NjbOVl3PVBAAAW7VqyElMTFRcXJwKCwudfbW1tdq+fbu8Xq8kyev1qrq6WsXFxU7Nxo0b1dTUpOTkZKfmww8/VENDg1NTUFCg/v37q1u3bk7N2d/TXNP8Pefjdrvl8Xj8NgAAYKeAQ86JEydUUlKikpISSX992LikpERlZWUKCgpSVlaW/vmf/1m///3vtXfvXv30pz9Vr169dO+990qSBg4cqDvvvFPTpk3Tjh079Kc//UmZmZl64IEH1KtXL0nSP/7jP8rlcmnq1Knav3+/Vq1apcWLF/s9aPzYY49p/fr1WrBggQ4ePKhnnnlGu3btUmZm5qXPCgAA6PQCfvB4165duu2225zPzcEjPT1d+fn5mj17tk6ePKlHHnlE1dXVuummm7R+/XrnHTmS9NZbbykzM1N33HGHgoODNX78eL300ktOe2RkpN5//31lZGQoKSlJMTExmjNnjrN8XJJuuOEGrVixQk899ZR+8Ytf6Nprr9W7777bId6RAwAA2l/AIefWW2+VMeaC7UFBQXruuef03HPPXbCme/fuzov/LmTo0KH66KOPLlpz//336/7777/4gAEAwBWJ364C2gG/YA4Alx8hB2hD/II5ALQdQg7QhvgFcwBoO4QcoB205G3YAIDAXFFvPAYAAFcOQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACuxhBzoZHhbMgB8P4QcoJPgbckAEBhCDtBJ8LZkAAgMIQfoZHhbMgB8Pzx4DAAArETIAQAAViLkAAAAK/FMDnAFaenyc4kl6AA6H0IOcAW41OXnEkvQAXQ+hBzgCnApy88llqAD6JwIOcAVhOXnAK4kPHgMAACsRMgBAABW4nYVgO+NHwcF0JkQcgB8J34cFEBnRMgB8J34cVAAnREhB8D3xuosAJ0JDx4DAAArEXIAAICVuF0FoE2wMgtAWyPkALisWJkFoL0QcgBcVqzMAtBeCDkA2gQrswC0NR48BgAAVuJKDoAOj4eWAbQEIQdAh8VDywAuBSEHQIfVGg8tf/TRRxo4cGDA381VIKDzI+QA6PBa8tAyV4EAEHIAWIml6wAIOQCsdilL11v6wHNdXZ3cbneL+nKbDGg9hBwA+JZLvdWloGDJNLWoK7fJgNZDyAGAb7mUW12nPt+lmo/e5DYZ0AEQcgDgAlpyq6vhaHmL+zZrj9tk3GKDjQg5ANBBtOdtMm6xwUaEHADoINrrNllr3GLjfUToiAg5ANDBtPVtskvpe6lXn9zuMP33f/+XevbsGXBfAhK+CyEHANBil3L16fT/7Vf1xtd01113tei7CUj4LoQcAMAla/EVpHYKSDxHdGUg5AAA2lVbB6RLfY6IlWidByEHANBptcdzRKxE6zwIOQCAKwove7xyEHIAAFekzvayR251BY6QAwBAG2C5fdsj5AAA0AY643L7ll516igIOQAAtKHOtty+MyPkAADQSbR1QGp+0LqzIuQAAHAFuJQHrTur4PYeAAAAwOVAyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYKVOH3Ly8vLUt29fhYWFKTk5WTt27GjvIQEAgA6gU4ecVatWKTs7W3PnztXu3bs1bNgwpaamqrKysr2HBgAA2lmnDjkLFy7UtGnTNHnyZA0aNEhLly5VRESEli1b1t5DAwAA7azTvvG4vr5excXFysnJcfYFBwcrJSVFRUVF5+1TV1enuro653NNTY0kqba2tlXHduLEib9+n+8zNdWfDqhv89sl6UvfjtK3Pb+bvvSlbyfue+z/JP31b2Jr/51tPp4x5uKFppP64osvjCSzdetWv/2zZs0yo0aNOm+fuXPnGklsbGxsbGxsFmzl5eUXzQqd9kpOS+Tk5Cg7O9v53NTUpGPHjik6OlpBQUEX7FdbW6v4+HiVl5fL4/G0xVCvSMxz22Gu2wbz3HaY67bRUebZGKOvv/5avXr1umhdpw05MTExCgkJUUVFhd/+iooKxcXFnbeP2+2W2+322xcVFfW9v9Pj8fAfTxtgntsOc902mOe2w1y3jY4wz5GRkd9Z02kfPHa5XEpKSlJhYaGzr6mpSYWFhfJ6ve04MgAA0BF02is5kpSdna309HSNHDlSo0aN0osvvqiTJ09q8uTJ7T00AADQzjp1yJkwYYK++uorzZkzRz6fT8OHD9f69esVGxvbqt/jdrs1d+7cc251oXUxz22HuW4bzHPbYa7bRmeb5yBjvmv9FQAAQOfTaZ/JAQAAuBhCDgAAsBIhBwAAWImQAwAArETI+Q55eXnq27evwsLClJycrB07drT3kDqV3Nxc/ehHP9LVV1+tHj166N5779WhQ4f8ak6fPq2MjAxFR0era9euGj9+/DkveSwrK1NaWpoiIiLUo0cPzZo1S2fOnGnLU+lU5s2bp6CgIGVlZTn7mOfW88UXX2jSpEmKjo5WeHi4hgwZol27djntxhjNmTNHPXv2VHh4uFJSUvTpp5/6HePYsWOaOHGiPB6PoqKiNHXqVOd37/BXjY2Nevrpp5WYmKjw8HD9zd/8jZ5//nm/3ytirgP34Ycf6u6771avXr0UFBSkd99916+9teb0k08+0c0336ywsDDFx8dr/vz5l/vUznXpvyJlr5UrVxqXy2WWLVtm9u/fb6ZNm2aioqJMRUVFew+t00hNTTXLly83+/btMyUlJeYnP/mJSUhIMCdOnHBqpk+fbuLj401hYaHZtWuXGT16tLnhhhuc9jNnzpjBgweblJQUs2fPHrNu3ToTExNjcnJy2uOUOrwdO3aYvn37mqFDh5rHHnvM2c88t45jx46ZPn36mJ/97Gdm+/bt5vPPPzcbNmwwn332mVMzb948ExkZad59913z8ccfm7//+783iYmJ5tSpU07NnXfeaYYNG2a2bdtmPvroI9OvXz/z4IMPtscpdVgvvPCCiY6ONmvWrDGHDx82q1evNl27djWLFy92apjrwK1bt8788pe/NL/97W+NJPPOO+/4tbfGnNbU1JjY2FgzceJEs2/fPvOb3/zGhIeHm1/96ldtdZrGGGMIORcxatQok5GR4XxubGw0vXr1Mrm5ue04qs6tsrLSSDKbN282xhhTXV1tQkNDzerVq52a0tJSI8kUFRUZY/76H2RwcLDx+XxOzZIlS4zH4zF1dXVtewId3Ndff22uvfZaU1BQYP7u7/7OCTnMc+t54oknzE033XTB9qamJhMXF2f+7d/+zdlXXV1t3G63+c1vfmOMMebAgQNGktm5c6dT84c//MEEBQWZL7744vINvpNJS0szU6ZM8ds3btw4M3HiRGMMc90avh1yWmtOX331VdOtWze//3c88cQTpn///pf5jPxxu+oC6uvrVVxcrJSUFGdfcHCwUlJSVFRU1I4j69xqamokSd27d5ckFRcXq6GhwW+eBwwYoISEBGeei4qKNGTIEL+XPKampqq2tlb79+9vw9F3fBkZGUpLS/ObT4l5bk2///3vNXLkSN1///3q0aOHrr/+ev3617922g8fPiyfz+c315GRkUpOTvab66ioKI0cOdKpSUlJUXBwsLZv3952J9PB3XDDDSosLNSf//xnSdLHH3+sLVu2aOzYsZKY68uhtea0qKhIt9xyi1wul1OTmpqqQ4cO6fjx4210Np38jceXU1VVlRobG895e3JsbKwOHjzYTqPq3JqampSVlaUbb7xRgwcPliT5fD65XK5zfig1NjZWPp/PqTnfv4fmNvzVypUrtXv3bu3cufOcNua59Xz++edasmSJsrOz9Ytf/EI7d+7UP/3TP8nlcik9Pd2Zq/PN5dlz3aNHD7/2Ll26qHv37sz1WZ588knV1tZqwIABCgkJUWNjo1544QVNnDhRkpjry6C15tTn8ykxMfGcYzS3devW7bKM/9sIOWgzGRkZ2rdvn7Zs2dLeQ7FOeXm5HnvsMRUUFCgsLKy9h2O1pqYmjRw5Uv/yL/8iSbr++uu1b98+LV26VOnp6e08Oru8/fbbeuutt7RixQpdd911KikpUVZWlnr16sVc43vhdtUFxMTEKCQk5JzVJxUVFYqLi2unUXVemZmZWrNmjT744AP17t3b2R8XF6f6+npVV1f71Z89z3Fxcef999Dchr/ejqqsrNSIESPUpUsXdenSRZs3b9ZLL72kLl26KDY2lnluJT179tSgQYP89g0cOFBlZWWS/v9cXez/HXFxcaqsrPRrP3PmjI4dO8Zcn2XWrFl68skn9cADD2jIkCF66KGHNHPmTOXm5kpiri+H1prTjvL/E0LOBbhcLiUlJamwsNDZ19TUpMLCQnm93nYcWedijFFmZqbeeecdbdy48ZzLl0lJSQoNDfWb50OHDqmsrMyZZ6/Xq7179/r9R1VQUCCPx3POH5sr1R133KG9e/eqpKTE2UaOHKmJEyc6/8w8t44bb7zxnNcg/PnPf1afPn0kSYmJiYqLi/Ob69raWm3fvt1vrqurq1VcXOzUbNy4UU1NTUpOTm6Ds+gcvvnmGwUH+/+ZCgkJUVNTkyTm+nJorTn1er368MMP1dDQ4NQUFBSof//+bXarShJLyC9m5cqVxu12m/z8fHPgwAHzyCOPmKioKL/VJ7i4GTNmmMjISLNp0yZz5MgRZ/vmm2+cmunTp5uEhASzceNGs2vXLuP1eo3X63Xam5c2jxkzxpSUlJj169ebH/zgByxt/g5nr64yhnluLTt27DBdunQxL7zwgvn000/NW2+9ZSIiIsybb77p1MybN89ERUWZ3/3ud+aTTz4x99xzz3mX4F5//fVm+/btZsuWLebaa6+9opc1n096erq55pprnCXkv/3tb01MTIyZPXu2U8NcB+7rr782e/bsMXv27DGSzMKFC82ePXvM//7v/xpjWmdOq6urTWxsrHnooYfMvn37zMqVK01ERARLyDual19+2SQkJBiXy2VGjRpltm3b1t5D6lQknXdbvny5U3Pq1Cnz85//3HTr1s1ERESY++67zxw5csTvOH/5y1/M2LFjTXh4uImJiTGPP/64aWhoaOOz6Vy+HXKY59bz3nvvmcGDBxu3220GDBhg/uM//sOvvampyTz99NMmNjbWuN1uc8cdd5hDhw751Rw9etQ8+OCDpmvXrsbj8ZjJkyebr7/+ui1Po8Orra01jz32mElISDBhYWHmhz/8ofnlL3/ptyyZuQ7cBx98cN7/L6enpxtjWm9OP/74Y3PTTTcZt9ttrrnmGjNv3ry2OkVHkDFnvToSAADAEjyTAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICV/h8Eb2LYV8xALgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(seq_lengths, bins=30, edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfa152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Adjust for Llama 3.1 if needed\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031387f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./llama3-java-finetune\",\n",
    "    per_device_train_batch_size=4,  # Adjust based on GPU memory\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,  \n",
    "    learning_rate=2e-4,\n",
    "    bf16=True,\n",
    "    save_steps=1000,\n",
    "    logging_steps=100,\n",
    "    report_to=\"wandb\"\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # For causal LM\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31a9816",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33489c8",
   "metadata": {},
   "source": [
    "## Un-Focus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa865bb",
   "metadata": {},
   "source": [
    "### HuggingFace Finetuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6a7551",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"karpathy/tiny_shakespeare\")\n",
    "print(dataset)\n",
    "# print('hlelow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe78681",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_size='left')\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_8bit=True,  # Optional: saves memory\n",
    "    device_map=\"auto\",\n",
    "    # torch_dtype=\"auto\"\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311769d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    'What is 5+5?', \n",
    "    'Tell me a poem.',\n",
    "    'Tell me a story.',\n",
    "]\n",
    "message_template = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a friendly, helpful chatbot.\"},\n",
    "    {\"role\": \"user\", \"content\": ''},\n",
    "]\n",
    "\n",
    "def qualitative_eval():\n",
    "    out = []\n",
    "    for question in questions:\n",
    "        message = message_template\n",
    "        message[1]['content'] = question\n",
    "\n",
    "        model_inputs = tokenizer.apply_chat_template(message, add_generation_prompt=True, return_tensors='pt').to('cuda')\n",
    "        generated_ids = model.generate(model_inputs, do_sample=True, max_new_tokens=50)\n",
    "        text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0].split('assistant')[-1]\n",
    "\n",
    "        out.append(text)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfebac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"])\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29a3414",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 256\n",
    "\n",
    "def group_texts(examples):\n",
    "    concatenated = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated[\"input_ids\"])\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "lm_dataset = tokenized_dataset.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    num_proc=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19724db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./llama3-shakespeare\",\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    bf16=True,\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee09556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_dataset[\"train\"],\n",
    "    eval_dataset=lm_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5515a2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualitative_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ecdcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./llama3-shakespeare\")\n",
    "tokenizer.save_pretrained(\"./llama3-shakespeare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cee218",
   "metadata": {},
   "source": [
    "### HuggingFace Training (0/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6977b840",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_dataset('wikitext', 'wikitext-2-raw-v1')\n",
    "datasets['train']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440dac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"]).to('cuda')\n",
    "\n",
    "model_checkpoint = \"distilgpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c8993",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = tokenizer.model_max_length\n",
    "\n",
    "first = True\n",
    "my_result = ...\n",
    "counter = 0\n",
    "\n",
    "def group_texts(examples):\n",
    "    global my_result, counter, first\n",
    "\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "\n",
    "    counter += 1\n",
    "    if first:\n",
    "        my_result = result\n",
    "        first = False\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43dc7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    # num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40ca80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint, device_map='auto', torch_dtype='auto')\n",
    "\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-wikitext2\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4026b363",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"validation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45d5f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cf5dbb",
   "metadata": {},
   "source": [
    "### HuggingFace Training (2/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1d4529",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side='left')\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map='auto', torch_dtype='auto')\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87bcd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    'What is 5+5?', \n",
    "    'Tell me a poem.',\n",
    "    'Tell me a story.',\n",
    "]\n",
    "message_template = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a friendly, helpful chatbot.\"},\n",
    "    {\"role\": \"user\", \"content\": ''},\n",
    "]\n",
    "\n",
    "def qualitative_eval():\n",
    "    out = []\n",
    "    for question in questions:\n",
    "        message = message_template\n",
    "        message[1]['content'] = question\n",
    "\n",
    "        model_inputs = tokenizer.apply_chat_template(message, add_generation_prompt=True, return_tensors='pt').to('cuda')\n",
    "        generated_ids = model.generate(model_inputs, do_sample=True, max_new_tokens=50)\n",
    "        text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0].split('assistant')[-1]\n",
    "\n",
    "        out.append(text)\n",
    "    \n",
    "    return out\n",
    "\n",
    "out = qualitative_eval()\n",
    "# for sentence in out:\n",
    "#     print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571345da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return tokenizer(text['text'])\n",
    "\n",
    "dataset = load_dataset('karpathy/tiny_shakespeare', trust_remote_code=True)\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True, remove_columns='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fbf3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 1028\n",
    "\n",
    "def group_text(input):\n",
    "    length = len(input['input_ids'])\n",
    "    n_batches = length // block_size\n",
    "\n",
    "    result = dict()\n",
    "\n",
    "    for k, t in input.items():\n",
    "        t = np.array(t[:n_batches * block_size])\n",
    "        t = einops.rearrange(t, '(bat block) -> bat block', bat=n_batches)\n",
    "        t = t.tolist()\n",
    "\n",
    "        result[k] = t\n",
    "\n",
    "    result['labels'] = result['input_ids'].copy()\n",
    "    return result\n",
    "\n",
    "lm_dataset = tokenized_dataset.map(group_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c9958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    f\"finetuned-tiny-shakespeare\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_dataset[\"train\"],\n",
    "    eval_dataset=lm_dataset[\"validation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67594927",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942a19e6",
   "metadata": {},
   "source": [
    "### HuggingFace Training (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb524c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', padding_side='left')\n",
    "# model = AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', device_map='auto', torch_dtype='auto')\n",
    "# tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25135ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_dataset = load_dataset('yelp_review_full')\n",
    "ft_tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-cased')\n",
    "\n",
    "def tokenize(examples):\n",
    "    return ft_tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True).to('cuda')\n",
    "dataset = ft_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b281df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565f0dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"yelp_review_classifier\",\n",
    "    eval_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58a218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train = dataset[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval = dataset[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fddacef",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train,\n",
    "    eval_dataset=small_eval,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf08ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d66b65b",
   "metadata": {},
   "source": [
    "### HuggingFace Practice  \n",
    "*getting comfortable with HF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5a0003",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', padding_side=\"left\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        'meta-llama/Llama-3.1-8B-Instruct', \n",
    "        device_map = 'auto',\n",
    "        torch_dtype = 'auto',\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb1f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'Jack n jill went up the hill to smoke a lot of pot',\n",
    "    'Beautiful world, where are you?',\n",
    "    'In the beginning, the universe was created. This was widely regarded as a bad move.',\n",
    "]\n",
    "\n",
    "out = tokenizer(sentences, padding=True, return_tensors='pt')['input_ids']\n",
    "\n",
    "\n",
    "out2 = tokenizer.decode(out[0])\n",
    "\n",
    "out3 = tokenizer.batch_decode(out, skip_special_tokens=True)\n",
    "\n",
    "print(out2 + '\\n')\n",
    "print(out)\n",
    "\n",
    "out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4faf3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"What is 5+5? Reply with a single word.\"\n",
    "model_inputs = tokenizer(test_sentence, return_tensors='pt').to('cuda')\n",
    "\n",
    "generated = model.generate(**model_inputs, max_new_tokens=100, temperature=0.3, repetition_penalty= 2.0)\n",
    "out = tokenizer.batch_decode(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f71a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47eaac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a friendly, helpful chatbot.\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"What is 5+5? Answer with a single word.\"},\n",
    "]\n",
    "\n",
    "model_inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "generated_ids = model.generate(model_inputs, do_sample=True, max_new_tokens=50)\n",
    "print(tokenizer.batch_decode(generated_ids)[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bb4c3c",
   "metadata": {},
   "source": [
    "### LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97028351",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda333b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create LoRA configuration object\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, # type of task to train on\n",
    "    inference_mode=False, # set to False for training\n",
    "    r=8, \n",
    "    lora_alpha=32, \n",
    "    lora_dropout=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e871434",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_adapter(lora_config, adapter_name=\"lora_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59a7e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c9b376",
   "metadata": {},
   "source": [
    "### Async Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f066329",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def task1():\n",
    "    print(\"Task 1: Start\")\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"Task 1: End\")\n",
    "\n",
    "async def task2():\n",
    "    print(\"Task 2: Start\")\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"Task 2: End\")\n",
    "\n",
    "# async def main():\n",
    "await asyncio.gather(task1(), task2())\n",
    "\n",
    "# await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5f9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat_async():\n",
    "    prompt = 'hello world'\n",
    "    client = AsyncOpenAI()\n",
    "\n",
    "    response = await client.responses.create(\n",
    "        model = 'gpt-4.1-mini',\n",
    "        input = prompt,\n",
    "    )\n",
    "\n",
    "    text_out = response.output[-1].content[0].text\n",
    "    return text_out\n",
    "\n",
    "def chat_reg():\n",
    "    prompt = 'hello world'\n",
    "    client = OpenAI()\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model = 'gpt-4.1-mini',\n",
    "        input = prompt,\n",
    "    )\n",
    "\n",
    "    text_out = response.output[-1].content[0].text\n",
    "    return text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d13db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chat_async()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
