{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73c1567d",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4417b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "from typing import List\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import inspect_ai\n",
    "from openai import OpenAI\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "import torch as t\n",
    "import subprocess\n",
    "import contextlib\n",
    "import shutil\n",
    "import ast\n",
    "import textwrap\n",
    "import copy\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a53e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect_ai import Task, task\n",
    "from inspect_ai.dataset import Sample, hf_dataset\n",
    "from inspect_ai.util import ExecResult, sandbox\n",
    "from inspect_ai.scorer import CORRECT, INCORRECT, Score, Scorer, Target, accuracy, scorer, stderr\n",
    "from inspect_ai.solver import TaskState, generate\n",
    "from inspect_ai.model import get_model\n",
    "from inspect_ai.log import read_eval_log\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4a4c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "login(token = os.environ['HF_TOKEN'])\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34683c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORT_HELPER = {\n",
    "    \"python\": [\n",
    "        \"import math\",\n",
    "        \"import re\",\n",
    "        \"import sys\",\n",
    "        \"import copy\",\n",
    "        \"import datetime\",\n",
    "        \"import itertools\",\n",
    "        \"import collections\",\n",
    "        \"import heapq\",\n",
    "        \"import statistics\",\n",
    "        \"import functools\",\n",
    "        \"import hashlib\",\n",
    "        \"import numpy\",\n",
    "        \"import numpy as np\",\n",
    "        \"import string\",\n",
    "        \"from typing import *\",\n",
    "        \"from collections import *\",\n",
    "    ],\n",
    "    \"go\"    : [\n",
    "        \"math\",\n",
    "        \"strings\",\n",
    "        \"fmt\",\n",
    "        \"strconv\",\n",
    "        \"time\",\n",
    "        \"bytes\",\n",
    "        \"regexp\",\n",
    "        \"sort\",\n",
    "        \"math/rand\",\n",
    "        \"crypto/md5\",\n",
    "    ],\n",
    "    \"cpp\"   : [\n",
    "        \"#include<stdlib.h>\",\n",
    "        \"#include<algorithm>\",\n",
    "        \"#include<math.h>\",\n",
    "        \"#include<stdio.h>\",\n",
    "        \"#include<vector>\",\n",
    "        \"#include<string>\",\n",
    "        \"#include<climits>\",\n",
    "        \"#include<cstring>\",\n",
    "        \"#include<iostream>\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# instruction prepended to code problem\n",
    "HUMANEVAL_INSTRUCTION = \"\"\"\n",
    "Read the following function signature and docstring, and fully implement\n",
    "the function described. Your response should only contain the code for\n",
    "this function.\\n\n",
    "\"\"\"\n",
    "\n",
    "CODE_EXTRACTION_INSTRUCTION = \"\"\"\n",
    "Here is a section of code. Follow these instructions to extract the function body.\n",
    "First, if present, remove any initial package names, import statements, and comments. \n",
    "Next, remove the function signature of the first function you see. \n",
    "If there is a `main` function present, delete that entire function. \n",
    "However, if there are any other functions present, leave them as they are.\n",
    "\n",
    "Your response should only contain the remaining block of code. \\n\n",
    "\"\"\"\n",
    "\n",
    "LANG_PREFIX = {\n",
    "    \"cpp\"          : \"// language: C++\",\n",
    "    \"java\"         : \"// language: Java\",\n",
    "    \"js\"           : \"// language: JavaScript\",\n",
    "    \"javascript\"   : \"// language: JavaScript\",\n",
    "    \"go\"           : \"// language: Go\",\n",
    "    \"python\"       : \"# language: Python\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46096290",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(\n",
    "        'hf/meta-llama/Llama-3.1-8B-Instruct', \n",
    "        device = 'auto',\n",
    "        torch_dtype=t.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f264e082",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d97a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_jsonl_all(filename: str):\n",
    "    results = []\n",
    "    fp = gzip.open(open(filename, \"rb\"), \"rt\")\n",
    "    for line in fp:\n",
    "        if any(not x.isspace() for x in line):\n",
    "            results.append(json.loads(line))\n",
    "    fp.close()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c1d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_content = stream_jsonl_all('data/python_data.gz')\n",
    "cpp_content = stream_jsonl_all('data/cpp_data.gz')\n",
    "go_content = stream_jsonl_all('data/go_data.gz')\n",
    "java_content = stream_jsonl_all('data/java_data.gz')\n",
    "js_content = stream_jsonl_all('data/js_data.gz')\n",
    "content = [python_content, cpp_content, go_content, java_content, js_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8c1e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "generations = stream_jsonl_all('data/python_generations.gz')\n",
    "generations[0]['generation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08897aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in content:\n",
    "    print(lang[0].keys())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560a2490",
   "metadata": {},
   "source": [
    "### LLM output => code  \n",
    "*I need to see LLM output & transform that into code*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feaf33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Go\n",
    "#     `cd ~/`  \n",
    "#     `GO_VERSION=1.24.5`  \n",
    "#     `wget https://go.dev/dl/go${GO_VERSION}.linux-amd64.tar.gz`  \n",
    "#     `rm -rf /usr/local/go`  \n",
    "#     `tar -C /usr/local -xzf go${GO_VERSION}.linux-amd64.tar.gz`  \n",
    "#     `echo 'export PATH=$PATH:/usr/local/go/bin' >> ~/.bashrc`  \n",
    "#     `export PATH=$PATH:/usr/local/go/bin`  \n",
    "#     `go version`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce73ce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND CODE\n",
    "\n",
    "def remove_fxn_signature(completion):\n",
    "    prompt = CODE_EXTRACTION_INSTRUCTION + completion\n",
    "    response = client.responses.create(\n",
    "        model='gpt-4.1-mini',\n",
    "        input=prompt\n",
    "    )\n",
    "\n",
    "    text_out = response.output[-1].content[0].text\n",
    "    return text_out\n",
    "\n",
    "def balance_brackets(completion):\n",
    "    if '{' in completion[:3]:\n",
    "        completion = completion.replace('{', \"\", 1)\n",
    "\n",
    "    difference = completion.count('{') - completion.count('}') \n",
    "    if difference == 0: \n",
    "        completion += '\\n}'\n",
    "        difference -= 1\n",
    "    if difference != -1: \n",
    "        print('brackets ain\\'t balancing')\n",
    "    \n",
    "    return completion\n",
    "\n",
    "\n",
    "def identify_codeblock(completion):\n",
    "    # remove lang flag\n",
    "    pattern_1 = re.compile(r\"```go\\n(.*?)```\", re.DOTALL)\n",
    "    pattern_2 = re.compile(r\"```\\n(.*?)```\", re.DOTALL)\n",
    "    matches = pattern_1.findall(completion) + pattern_2.findall(completion)\n",
    "\n",
    "    if matches == []:\n",
    "        return completion\n",
    "    else:\n",
    "        return matches[0]\n",
    "\n",
    "def find_code_go(completion: str) -> str:\n",
    "    processed = remove_fxn_signature(completion)\n",
    "    processed = identify_codeblock(processed)\n",
    "    processed = balance_brackets(processed)\n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6534bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_go(state, completion):\n",
    "    import_string = state.metadata['import']\n",
    "    prompt = state.metadata['prompt'].replace(import_string, '')\n",
    "\n",
    "    test = state.metadata['test']\n",
    "    test_setup = state.metadata['test_setup']\n",
    "    other_pkgs = []\n",
    "\n",
    "    for pkg in IMPORT_HELPER['go']:\n",
    "        if pkg not in test_setup:\n",
    "            p = pkg.split('/')[-1]\n",
    "            if p + '.' in completion:    \n",
    "                other_pkgs.append(f\"\\\"{pkg}\\\"\")\n",
    "    if other_pkgs:\n",
    "        import_other_pkgs = \"import (\\n\" + \"    \".join([p + \"\\n\" for p in other_pkgs]) + \")\"\n",
    "        final_code = test_setup + \"\\n\" + import_other_pkgs + \"\\n\" + prompt + completion + \"\\n\" + test\n",
    "    else:\n",
    "        final_code = test_setup + \"\\n\" + prompt + completion + \"\\n\" + test\n",
    "\n",
    "    return final_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5693bf",
   "metadata": {},
   "source": [
    "#### Running Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922904de",
   "metadata": {},
   "outputs": [],
   "source": [
    "@scorer(metrics=[accuracy(), stderr()])\n",
    "def go_scorer() -> Scorer:\n",
    "    async def score(state: TaskState, target: Target) -> Score:\n",
    "        task_id = state.sample_id\n",
    "        idx = int(task_id.split('/')[-1])\n",
    "\n",
    "        model_completion = state.output.completion\n",
    "        processed_completion = find_code_go(model_completion)\n",
    "        final_code = get_final_go(state, processed_completion)\n",
    "\n",
    "        tmp_dir = f'/root/srf-project/tmp/test_{idx}/'\n",
    "        if not os.path.exists(tmp_dir):\n",
    "            os.makedirs(tmp_dir, exist_ok=True)\n",
    "        file = os.path.join(tmp_dir, 'main_test.go')\n",
    "\n",
    "        with contextlib.chdir(tmp_dir):\n",
    "            open(file, 'w').write(final_code)\n",
    "            if not os.path.exists('go.mod'):\n",
    "                try:\n",
    "                    subprocess.run(['/usr/local/go/bin/go', 'mod', 'init', f'example.com/tmpmod_{idx}'],check=True, capture_output=True,)\n",
    "                except subprocess.CalledProcessError as e:\n",
    "                    print(\"Error running go mod init:\")\n",
    "                    print(e.stderr)\n",
    "            subprocess.run(['/usr/local/go/bin/go', 'mod', 'tidy'], check=True, capture_output=True,)\n",
    "\n",
    "        try:\n",
    "            result = await sandbox().exec(\n",
    "                cmd=[\"/usr/local/go/bin/go\", \"test\", file],\n",
    "                timeout=30,\n",
    "                cwd=tmp_dir\n",
    "            )\n",
    "        except TimeoutError:\n",
    "            result = ExecResult(False, 1, \"\", \"Verification timed out.\")\n",
    "\n",
    "        shutil.rmtree(tmp_dir)\n",
    "\n",
    "        return Score(\n",
    "            value=CORRECT if result.success else INCORRECT,\n",
    "            explanation=\"\".join(\n",
    "                [\"The following verification code was executed:\\n\\n\"]\n",
    "                + [final_code]\n",
    "                + [f\"\\nThe submission was incorrect\\n\\n{result.stderr}\"]\n",
    "                if not result.success\n",
    "                else [\"\"]\n",
    "            ),\n",
    "            metadata={\n",
    "                'completion': model_completion,\n",
    "                'processed': processed_completion,\n",
    "                'final_code': final_code,\n",
    "                'idx': idx,\n",
    "                'task_id': task_id,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d552c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'go'\n",
    "\n",
    "def humaneval_record_to_sample(record):\n",
    "    model_input = HUMANEVAL_INSTRUCTION + LANG_PREFIX[lang] + '\\n' + record['prompt'] \n",
    "\n",
    "    idx = int(record['task_id'].split('/')[-1])\n",
    "\n",
    "    metadata = {\n",
    "        \"prompt\": record[\"prompt\"],\n",
    "        \"test\": record[\"test\"],\n",
    "    }\n",
    "    if lang == 'go':\n",
    "        metadata['import'] = go_content[idx]['import']\n",
    "        metadata['test_setup'] = go_content[idx]['test_setup']\n",
    "    \n",
    "    return Sample(\n",
    "        id=record[\"task_id\"],\n",
    "        input=model_input,\n",
    "        target=record[\"canonical_solution\"],\n",
    "        metadata=metadata,\n",
    "    )\n",
    "\n",
    "humaneval_dataset = hf_dataset(\n",
    "    path = 'THUDM/humaneval-x',\n",
    "    name = lang,\n",
    "    split = 'test',\n",
    "    sample_fields = humaneval_record_to_sample,\n",
    "    trust = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d44cecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 164\n",
    "\n",
    "@task\n",
    "def humaneval():\n",
    "    return Task(\n",
    "        dataset = humaneval_dataset[:samples],\n",
    "        solver = generate(),\n",
    "        scorer = go_scorer(),\n",
    "        sandbox = 'local',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ebd63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "inspect_ai.eval(humaneval(), model = model, epochs = epochs)\n",
    "inspect_ai.eval(humaneval(), model = 'openai/gpt-4o-mini', epochs = epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c1b7de",
   "metadata": {},
   "source": [
    "#### Checking outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5b712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "\n",
    "log = read_eval_log('/root/srf-project/logs/test_3.eval')\n",
    "data = log.samples[idx].scores['go_scorer'].metadata\n",
    "canonical = log.samples[idx].target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa1bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(identify_codeblock(data['completion']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6d47e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee875a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = find_code_go(data['completion'])\n",
    "print(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a933743",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_id = 145\n",
    "idx = 0\n",
    "model_out = ''\n",
    "\n",
    "for i, sample in enumerate(log.samples):\n",
    "    id = int(sample.id.split('/')[-1])\n",
    "    if id == target_id:\n",
    "        idx = i\n",
    "        model_out = sample.messages[-1].content\n",
    "        print(i)\n",
    "        print()\n",
    "        print(model_out)\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
