{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25e28b2a",
   "metadata": {},
   "source": [
    "## Imports + Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edddd561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "from typing import List\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import inspect_ai\n",
    "from openai import OpenAI\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "import torch as t\n",
    "import subprocess\n",
    "import contextlib\n",
    "import shutil\n",
    "import ast\n",
    "import copy\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "146feabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect_ai import Task, task\n",
    "from inspect_ai.dataset import Sample, hf_dataset\n",
    "from inspect_ai.util import ExecResult, sandbox\n",
    "from inspect_ai.scorer import CORRECT, INCORRECT, Score, Scorer, Target, accuracy, scorer, stderr\n",
    "from inspect_ai.solver import TaskState, generate\n",
    "from inspect_ai.model import get_model\n",
    "from inspect_ai.log import read_eval_log\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fae427e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "login(token = os.environ['HF_TOKEN'])\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4bf8ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORT_HELPER = {\n",
    "    \"python\": [\n",
    "        \"import math\",\n",
    "        \"import re\",\n",
    "        \"import sys\",\n",
    "        \"import copy\",\n",
    "        \"import datetime\",\n",
    "        \"import itertools\",\n",
    "        \"import collections\",\n",
    "        \"import heapq\",\n",
    "        \"import statistics\",\n",
    "        \"import functools\",\n",
    "        \"import hashlib\",\n",
    "        \"import numpy\",\n",
    "        \"import numpy as np\",\n",
    "        \"import string\",\n",
    "        \"from typing import *\",\n",
    "        \"from collections import *\",\n",
    "    ],\n",
    "    \"go\"    : [\n",
    "        \"math\",\n",
    "        \"strings\",\n",
    "        \"fmt\",\n",
    "        \"strconv\",\n",
    "        \"time\",\n",
    "        \"bytes\",\n",
    "        \"regexp\",\n",
    "        \"sort\",\n",
    "        \"math/rand\",\n",
    "        \"crypto/md5\",\n",
    "    ],\n",
    "    \"cpp\"   : [\n",
    "        \"#include<stdlib.h>\",\n",
    "        \"#include<algorithm>\",\n",
    "        \"#include<math.h>\",\n",
    "        \"#include<stdio.h>\",\n",
    "        \"#include<vector>\",\n",
    "        \"#include<string>\",\n",
    "        \"#include<climits>\",\n",
    "        \"#include<cstring>\",\n",
    "        \"#include<iostream>\",\n",
    "        \"#include <numeric>\",\n",
    "        \"#include <sstream>\",\n",
    "        \"#include <stack>\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# instruction prepended to code problem\n",
    "HUMANEVAL_INSTRUCTION = \"\"\"\n",
    "Read the following function signature and docstring, and fully implement\n",
    "the function described. Your response should only contain the code for\n",
    "this function.\\n\n",
    "\"\"\"\n",
    "\n",
    "CODE_EXTRACTION_INSTRUCTION = \"\"\"\n",
    "Here is a section of code. Follow these instructions to extract the function body.\n",
    "First, if present, remove any initial package names, import statements, and comments. \n",
    "Next, remove the function signature of the first function you see. \n",
    "If there is a `main` function present, delete that entire function. \n",
    "However, if there are any other functions present, leave them as they are.\n",
    "\n",
    "Your response should only contain the remaining block of code. \\n\n",
    "\"\"\"\n",
    "\n",
    "LANG_PREFIX = {\n",
    "    \"cpp\"          : \"// language: C++\",\n",
    "    \"java\"         : \"// language: Java\",\n",
    "    \"js\"           : \"// language: JavaScript\",\n",
    "    \"javascript\"   : \"// language: JavaScript\",\n",
    "    \"go\"           : \"// language: Go\",\n",
    "    \"python\"       : \"# language: Python\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab12a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_model(\n",
    "#         'hf/meta-llama/Llama-3.1-8B-Instruct', \n",
    "#         device = 'auto',\n",
    "#         torch_dtype=t.bfloat16,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a725ebb6",
   "metadata": {},
   "source": [
    "### Language Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc5e47b2",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# JavaScript\n",
    "#     `apt-get update`  \n",
    "#     `apt-get install -y curl`  \n",
    "#     `curl -fsSL https://deb.nodesource.com/setup_lts.x | bash -`  \n",
    "#     `apt-get install -y nodejs`  \n",
    "#     verify installation: `node -v` // `npm -v` // `node -e \"console.log('Node.js is working')\"`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0284d1fd",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Java\n",
    "#     `apt-get update`  \n",
    "#     `apt-get install -y openjdk-21-jdk`  \n",
    "# Verify with:  \n",
    "#     `java -version`  \n",
    "#     `javac -version` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea4e9f29",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Go\n",
    "#     `cd ~/`  \n",
    "#     `GO_VERSION=1.24.5`  \n",
    "#     `wget https://go.dev/dl/go${GO_VERSION}.linux-amd64.tar.gz`  \n",
    "#     `rm -rf /usr/local/go`  \n",
    "#     `tar -C /usr/local -xzf go${GO_VERSION}.linux-amd64.tar.gz`  \n",
    "#     `echo 'export PATH=$PATH:/usr/local/go/bin' >> ~/.bashrc`  \n",
    "#     `export PATH=$PATH:/usr/local/go/bin`  \n",
    "#     `go version`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbfd5e21",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# C++\n",
    "#     apt-get update\n",
    "#     apt-get install -y g++\n",
    "#     apt-get install -y build-essential\n",
    "#     apt-get install libboost-all-dev\n",
    "#     apt-get install libssl-dev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27c2a4c",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0c435c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_jsonl_all(filename: str):\n",
    "    results = []\n",
    "    fp = gzip.open(open(filename, \"rb\"), \"rt\")\n",
    "    for line in fp:\n",
    "        if any(not x.isspace() for x in line):\n",
    "            results.append(json.loads(line))\n",
    "    fp.close()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8d9696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_content = stream_jsonl_all('data/python_data.gz')\n",
    "cpp_content = stream_jsonl_all('data/cpp_data.gz')\n",
    "go_content = stream_jsonl_all('data/go_data.gz')\n",
    "java_content = stream_jsonl_all('data/java_data.gz')\n",
    "js_content = stream_jsonl_all('data/js_data.gz')\n",
    "content = [python_content, cpp_content, go_content, java_content, js_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5952979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generations = stream_jsonl_all('data/python_generations.gz')\n",
    "generations[0]['generation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a531c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['task_id', 'prompt', 'canonical_solution', 'test', 'text', 'declaration', 'example_test'])\n",
      "dict_keys(['task_id', 'prompt', 'canonical_solution', 'test', 'declaration', 'example_test'])\n",
      "dict_keys(['task_id', 'prompt', 'import', 'docstring', 'declaration', 'canonical_solution', 'test', 'test_setup', 'example_test'])\n",
      "dict_keys(['task_id', 'prompt', 'canonical_solution', 'test', 'text', 'declaration', 'example_test'])\n",
      "dict_keys(['task_id', 'prompt', 'canonical_solution', 'test', 'declaration', 'example_test'])\n"
     ]
    }
   ],
   "source": [
    "for lang in content:\n",
    "    print(lang[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5c3a24",
   "metadata": {},
   "source": [
    "## Eval Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f034f0",
   "metadata": {},
   "source": [
    "### Extract Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edd2df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_codeblock(completion: str) -> str:\n",
    "    pattern_1 = re.compile(r\"```(?:python|javascript|java|cpp|go)\\n(.*?)```\", re.DOTALL)\n",
    "    pattern_2 = re.compile(r\"```\\n(.*?)```\", re.DOTALL)\n",
    "    matches = pattern_1.findall(completion) + pattern_2.findall(completion)\n",
    "\n",
    "    if matches == []:\n",
    "        return completion\n",
    "    else:\n",
    "        return matches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3b8d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_signature(completion):\n",
    "    prompt = CODE_EXTRACTION_INSTRUCTION + completion\n",
    "    response = client.responses.create(\n",
    "        model='gpt-4.1-mini',\n",
    "        input=prompt\n",
    "    )\n",
    "\n",
    "    text_out = response.output[-1].content[0].text\n",
    "    return text_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10b7a88",
   "metadata": {},
   "source": [
    "#### CPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2920892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_brackets_cpp(completion):\n",
    "    if '{' in completion[:3]:\n",
    "        completion = completion.replace('{', \"\", 1)\n",
    "\n",
    "    difference = completion.count('{') - completion.count('}') \n",
    "    if difference == 0: \n",
    "        completion += '}'\n",
    "        difference -= 1\n",
    "    if difference != -1: \n",
    "        print('brackets ain\\'t balancing')\n",
    "    \n",
    "    return completion\n",
    "\n",
    "def find_code_cpp(completion: str) -> str:\n",
    "    processed = remove_signature(completion)\n",
    "    processed = identify_codeblock(processed)\n",
    "    processed = balance_brackets_cpp(processed)\n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23dedc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_cpp(state, completion):\n",
    "    imports = ''\n",
    "    for s in IMPORT_HELPER['cpp']:\n",
    "        if s not in state.metadata['prompt']:\n",
    "            imports += s + '\\n'\n",
    "\n",
    "    code = imports + \"\\n\" + state.metadata['prompt'] + completion + \"\\n\" + state.metadata['test']\n",
    "    \n",
    "    return code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9114d0d7",
   "metadata": {},
   "source": [
    "#### Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6747847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_brackets_go(completion):\n",
    "    if '{' in completion[:3]:\n",
    "        completion = completion.replace('{', \"\", 1)\n",
    "\n",
    "    difference = completion.count('{') - completion.count('}') \n",
    "    if difference == 0: \n",
    "        completion += '\\n}'\n",
    "        difference -= 1\n",
    "    if difference != -1: \n",
    "        print('brackets ain\\'t balancing')\n",
    "    \n",
    "    return completion\n",
    "\n",
    "def find_code_go(completion: str) -> str:\n",
    "    processed = remove_signature(completion)\n",
    "    processed = identify_codeblock(processed)\n",
    "    processed = balance_brackets_go(processed)\n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3075cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_go(state, completion):\n",
    "    import_string = state.metadata['import']\n",
    "    prompt = state.metadata['prompt'].replace(import_string, '')\n",
    "\n",
    "    test = state.metadata['test']\n",
    "    test_setup = state.metadata['test_setup']\n",
    "    other_pkgs = []\n",
    "\n",
    "    for pkg in IMPORT_HELPER['go']:\n",
    "        if pkg not in test_setup:\n",
    "            p = pkg.split('/')[-1]\n",
    "            if p + '.' in completion:    \n",
    "                other_pkgs.append(f\"\\\"{pkg}\\\"\")\n",
    "    if other_pkgs:\n",
    "        import_other_pkgs = \"import (\\n\" + \"    \".join([p + \"\\n\" for p in other_pkgs]) + \")\"\n",
    "        final_code = test_setup + \"\\n\" + import_other_pkgs + \"\\n\" + prompt + completion + \"\\n\" + test\n",
    "    else:\n",
    "        final_code = test_setup + \"\\n\" + prompt + completion + \"\\n\" + test\n",
    "\n",
    "    return final_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1555b525",
   "metadata": {},
   "source": [
    "#### Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c9c510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unindented(lines, full_func):\n",
    "    while (not lines[0]) or (lines[0] == lines[0].lstrip()):\n",
    "        full_func = True\n",
    "    return lines, full_func\n",
    "\n",
    "def remove_signature_java(lines, full_func):\n",
    "    '''\n",
    "    deals with three cases\n",
    "    a) first lines are comments, before method header\n",
    "    b) first line is method-header\n",
    "    c) b), but with incorrect indentation? so header had accidentally been removed?\n",
    "    '''\n",
    "    if not (full_func or lines[0].lstrip()[:6] == 'public'):\n",
    "        return lines\n",
    "    \n",
    "    removed = False\n",
    "    og_lines = copy.deepcopy(lines)\n",
    "    \n",
    "    while not removed:\n",
    "        if lines == []:\n",
    "            return og_lines\n",
    "        \n",
    "        line = lines.pop(0)\n",
    "        if line.lstrip()[:6] == 'public':\n",
    "            removed = True\n",
    "        \n",
    "    return lines\n",
    "\n",
    "def balance_brackets_java(processed):\n",
    "    difference = processed.count('{') - processed.count('}') + 2\n",
    "    assert difference in [0, 1, 2], 'brackets ain\\'t balancing'\n",
    "    return processed + ('}' * difference)\n",
    "\n",
    "def find_code_java(completion: str) -> str:\n",
    "    code = identify_codeblock(completion)\n",
    "    lines = code.splitlines()\n",
    "    lines, full_func = remove_unindented(lines, False)\n",
    "    lines = remove_signature_java(lines, full_func)\n",
    "\n",
    "    processed = '\\n'.join(lines)\n",
    "    processed = balance_brackets_java(processed)\n",
    "    \n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f62716e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_java(state, completion):\n",
    "    final_code = state.metadata['prompt'] + completion + \"\\n\\n\" + state.metadata['test'] + \"\\n\"\n",
    "    return final_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8245571c",
   "metadata": {},
   "source": [
    "#### Java [archived]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d12cb33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_method_header(lines,):\n",
    "#     '''\n",
    "#     deals with three cases\n",
    "#     a) first lines are comments, before method header\n",
    "#     b) first line is method-header\n",
    "#     c) b), but with incorrect indentation? so header had accidentally been removed?\n",
    "#     '''\n",
    "#     removed = False\n",
    "#     og_lines = copy.deepcopy(lines)\n",
    "    \n",
    "#     while not removed:\n",
    "#         if lines == []:\n",
    "#             return og_lines\n",
    "        \n",
    "#         line = lines.pop(0)\n",
    "#         if line.lstrip()[:6] == 'public':\n",
    "#             removed = True\n",
    "        \n",
    "#     return lines\n",
    "\n",
    "# def balance_brackets(lines):\n",
    "#     final_code = '\\n'.join(lines)\n",
    "#     difference = final_code.count('{') - final_code.count('}') + 2\n",
    "#     assert difference in [0, 1, 2], 'brackets ain\\'t balancing'\n",
    "#     return final_code + ('}' * difference)\n",
    "\n",
    "# def remove_unindented(lines, full_func):\n",
    "#     import_statements = []\n",
    "#     while (not lines[0]) or (lines[0] == lines[0].lstrip()):\n",
    "#         line = lines.pop(0)\n",
    "#         full_func = True\n",
    "#         if 'import' in line: import_statements.append(line)\n",
    "    \n",
    "#     return lines, import_statements, full_func\n",
    "\n",
    "# def find_code_java(completion: str) -> str:\n",
    "#     code = identify_codeblock(completion)\n",
    "#     lines = code.splitlines()\n",
    "\n",
    "#     lines, import_statements, full_func = remove_unindented(lines, False)\n",
    "\n",
    "#     if full_func or lines[0].lstrip()[:6] == 'public':\n",
    "#         lines = remove_method_header(lines)\n",
    "\n",
    "#     processed_completion = balance_brackets(lines)\n",
    "#     import_statements = '\\n'.join(import_statements)\n",
    "    \n",
    "#     return processed_completion, import_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a99bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_final_java(imports, state, completion):\n",
    "#     final_code = imports + '\\n' + state.metadata['prompt'] + completion + \"\\n\\n\" + state.metadata['test'] + \"\\n\"\n",
    "#     return final_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51f2087",
   "metadata": {},
   "source": [
    "#### JavaScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "635e7a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_signature_js(code: str) -> str:\n",
    "    lines = code.splitlines()\n",
    "    found = False\n",
    "    for line in lines:\n",
    "        if line.lstrip().startswith('const'):\n",
    "            lines.remove(line)\n",
    "            found = True\n",
    "            break  \n",
    "\n",
    "    if not found: \n",
    "        print('error extracting function body')\n",
    "        return 'errormsg'\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def find_code_js(completion: str) -> str:\n",
    "    processed = identify_codeblock(completion)\n",
    "    processed = remove_signature_js(processed)\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78123532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_js(state, completion):\n",
    "    final_code = state.metadata['prompt'] + completion + \"\\n\\n\" + state.metadata['test'] + \"\\n\"\n",
    "    return final_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f360fc",
   "metadata": {},
   "source": [
    "#### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "372bc486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_signature_python(code: str) -> str:\n",
    "    try:\n",
    "        tree = ast.parse(code)\n",
    "        for node in tree.body:\n",
    "            if not isinstance(node, ast.FunctionDef):\n",
    "                continue\n",
    "            code_lines = code.splitlines()\n",
    "            start = node.body[0].lineno - 1\n",
    "            end = node.body[-1].end_lineno\n",
    "            body_lines = code_lines[start:end]\n",
    "            return \"\\n\".join(body_lines)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting function body: {e}\")\n",
    "        return \"errormsg\"\n",
    "    \n",
    "def find_code_python(completion):\n",
    "    processed = identify_codeblock(completion)\n",
    "    processed = remove_signature_python(processed)\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fefc1b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_python(state, completion):\n",
    "    imports = \"\\n\".join(IMPORT_HELPER[\"python\"]) + \"\\n\"\n",
    "    final_code = imports + state.metadata['prompt'] + completion + \"\\n\" + state.metadata['test'] + \"\\n\"\n",
    "    return final_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dffe12",
   "metadata": {},
   "source": [
    "### Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5278778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_code(completion, lang: str):\n",
    "    func = globals()[f'find_code_{lang}']\n",
    "    return func(completion)\n",
    "\n",
    "def get_final(state, lang, task_id):\n",
    "    model_completion = state.output.completion\n",
    "    processed_completion = find_code(model_completion, lang)\n",
    "\n",
    "    final = globals()[f'get_final_{lang}']\n",
    "    final_code = final(state, processed_completion)\n",
    "\n",
    "    if 'errormsg' in final_code:\n",
    "        print(f'error in sample: {task_id}')\n",
    "    \n",
    "    return final_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333ea676",
   "metadata": {},
   "source": [
    "### Scorers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5785fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def python_scorer(final_code, *args):\n",
    "    try:\n",
    "        result = await sandbox().exec(\n",
    "            cmd=[\"python\", \"-c\", final_code],\n",
    "            timeout=30,\n",
    "        )\n",
    "    except TimeoutError:\n",
    "        result = ExecResult(False, 1, \"\", \"Verification timed out.\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8fdfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def js_scorer(final_code, *args):\n",
    "    try:\n",
    "        result = await sandbox().exec(\n",
    "            cmd=[\"node\", \"-e\", final_code],\n",
    "            timeout=30,\n",
    "        )\n",
    "    except TimeoutError:\n",
    "        result = ExecResult(False, 1, \"\", \"Verification timed out.\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a340183",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def go_scorer(final_code, idx, tmp_dir):\n",
    "    if not os.path.exists(tmp_dir):\n",
    "        os.makedirs(tmp_dir, exist_ok=True)\n",
    "    file = os.path.join(tmp_dir, 'main_test.go')\n",
    "\n",
    "    with contextlib.chdir(tmp_dir):\n",
    "        open(file, 'w').write(final_code)\n",
    "        if not os.path.exists('go.mod'):\n",
    "            try:\n",
    "                subprocess.run(\n",
    "                    ['/usr/local/go/bin/go', 'mod', 'init', f'example.com/tmpmod_{idx}'],\n",
    "                    check=True, \n",
    "                    capture_output=True,\n",
    "                )\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(\"Error running go mod init:\")\n",
    "                print(e.stderr)\n",
    "        subprocess.run(\n",
    "            ['/usr/local/go/bin/go', 'mod', 'tidy'], \n",
    "            check=True, \n",
    "            capture_output=True,\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        result = await sandbox().exec(\n",
    "            cmd=[\"/usr/local/go/bin/go\", \"test\", file],\n",
    "            timeout=30,\n",
    "            cwd=tmp_dir\n",
    "        )\n",
    "    except TimeoutError:\n",
    "        result = ExecResult(False, 1, \"\", \"Verification timed out.\")\n",
    "\n",
    "    shutil.rmtree(tmp_dir)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcafb6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def java_scorer(final_code, idx, tmp_dir):\n",
    "    if not os.path.exists(tmp_dir):\n",
    "        os.makedirs(tmp_dir, exist_ok=True)\n",
    "    file = os.path.join(tmp_dir, 'Main.java')\n",
    "\n",
    "    with contextlib.chdir(tmp_dir):\n",
    "        open(file, 'w').write(final_code)\n",
    "    \n",
    "    try:\n",
    "        compile_proc = subprocess.run(\n",
    "            [\"javac\", \"Main.java\"],\n",
    "            cwd=tmp_dir,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=30  \n",
    "        )\n",
    "        if compile_proc.returncode != 0:\n",
    "            print(f\"Compilation failed! Idx: {idx}\")\n",
    "            print(\"stderr:\", compile_proc.stderr)\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"Compilation timed out!\")\n",
    "    except Exception as e:\n",
    "        print(\"Compilation error:\", e)\n",
    "\n",
    "    try:\n",
    "        result = await sandbox().exec(\n",
    "            cmd=[\"java\", \"-cp\", tmp_dir, \"Main\"],\n",
    "            timeout=30,\n",
    "        )\n",
    "    except TimeoutError:\n",
    "        result = ExecResult(False, 1, \"\", \"Verification timed out.\")\n",
    "\n",
    "    shutil.rmtree(tmp_dir)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f6bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def cpp_scorer(final_code, idx, tmp_dir):\n",
    "    if not os.path.exists(tmp_dir):\n",
    "        os.makedirs(tmp_dir, exist_ok=True)\n",
    "    file = os.path.join(tmp_dir, 'test.cpp')\n",
    "    executable = os.path.join(tmp_dir, 'test.out')\n",
    "\n",
    "    open(file, 'w').write(final_code)\n",
    "    \n",
    "    try:\n",
    "        compile_proc = subprocess.run(\n",
    "            [\"g++\", \"-std=c++17\", file, \"-o\", executable, '-lssl', '-lcrypto'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=30  # seconds, adjust as needed\n",
    "        )\n",
    "        if compile_proc.returncode != 0:\n",
    "            print(f\"Compilation failed! task number: {idx}\")\n",
    "            print(\"stderr:\", compile_proc.stderr)\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"Compilation timed out!\")\n",
    "\n",
    "    if os.path.exists(executable):\n",
    "        try:\n",
    "            result = await sandbox().exec(\n",
    "                cmd=[executable],\n",
    "                timeout=30\n",
    "            )\n",
    "        except TimeoutError:\n",
    "            result = ExecResult(False, 1, \"\", \"Verification timed out.\")\n",
    "        except Exception as e:\n",
    "            print(f'execution failed cuz of: {e}')\n",
    "    else:\n",
    "        result = ExecResult(False, 1, \"\", \"Compiler Error\")\n",
    "\n",
    "    shutil.rmtree(tmp_dir)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f3b45",
   "metadata": {},
   "source": [
    "### Inspect Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a859b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lang_idx(task_id: str):\n",
    "    lang, idx = task_id.split('/')\n",
    "    lang = lang.lower()\n",
    "    if lang == 'javascript':\n",
    "        lang = 'js'\n",
    "    idx = int(idx)\n",
    "\n",
    "    return lang, idx\n",
    "\n",
    "@scorer(metrics=[accuracy(), stderr()])\n",
    "def main_scorer() -> Scorer:\n",
    "    async def score(state: TaskState, target: Target) -> Score:\n",
    "        task_id = state.sample_id\n",
    "        lang, idx = get_lang_idx(task_id)\n",
    "\n",
    "        final_code = get_final(state, lang, task_id)\n",
    "\n",
    "        tmp_dir = f'/root/srf-project/test_humaneval-x/tmp/test_{idx}/'\n",
    "        my_scorer = globals()[f'{lang}_scorer']\n",
    "        result = my_scorer(final_code, idx, tmp_dir)\n",
    "\n",
    "        success = result.success and (result.stderr == '')\n",
    "        \n",
    "        return Score(\n",
    "            value=CORRECT if success else INCORRECT,\n",
    "            explanation=\"\".join(\n",
    "                [\"The following verification code was executed:\\n\\n\"]\n",
    "                + [final_code]\n",
    "                + [f\"\\nThe submission was incorrect\\n\\n{result.stderr}\"]\n",
    "                if not result.success\n",
    "                else [\"\"]\n",
    "            ),\n",
    "            metadata={\n",
    "                'completion': model_completion,\n",
    "                'processed': processed_completion,\n",
    "                'final_code': final_code,\n",
    "                'idx': idx,\n",
    "                'task_id': task_id,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b0d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = ...\n",
    "\n",
    "def humaneval_record_to_sample(record):\n",
    "    model_input = HUMANEVAL_INSTRUCTION + LANG_PREFIX[language] + '\\n' + record['prompt'] \n",
    "\n",
    "    idx = int(record['task_id'].split('/')[-1])\n",
    "\n",
    "    metadata = {\n",
    "        \"prompt\": record[\"prompt\"],\n",
    "        \"test\": record[\"test\"],\n",
    "    }\n",
    "    if language == 'go':\n",
    "        metadata['import'] = go_content[idx]['import']\n",
    "        metadata['test_setup'] = go_content[idx]['test_setup']\n",
    "    \n",
    "    return Sample(\n",
    "        id=record[\"task_id\"],\n",
    "        input=model_input,\n",
    "        target=record[\"canonical_solution\"],\n",
    "        metadata=metadata,\n",
    "    )\n",
    "\n",
    "humaneval_dataset = hf_dataset(\n",
    "    path = 'THUDM/humaneval-x',\n",
    "    name = language,\n",
    "    split = 'test',\n",
    "    sample_fields = humaneval_record_to_sample,\n",
    "    trust = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d1d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ...\n",
    "\n",
    "@task\n",
    "def humaneval():\n",
    "    return Task(\n",
    "        dataset = humaneval_dataset[:samples],\n",
    "        solver = generate(),\n",
    "        scorer = main_scorer(),\n",
    "        sandbox = 'local',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfee2300",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "inspect_ai.eval(humaneval(), model = ..., epochs = epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
